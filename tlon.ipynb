{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/k7tj7j8j0z1_ry92lnh0blg00000gn/T/ipykernel_9060/1751686986.py:7: DtypeWarning: Columns (7,17,56,58,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been sorted and saved to /Users/fabrizioferrari/Desktop/final boss/tlon/Training_Set.csv and /Users/fabrizioferrari/Desktop/final boss/tlon/Test_Set.csv\n"
     ]
    }
   ],
   "source": [
    "# sort and split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/fabrizioferrari/Desktop/OG.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure 'Fecha Cierre' is in datetime format\n",
    "df['Fecha Cierre'] = pd.to_datetime(df['Fecha Cierre'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# Ensure 'Fecha Colocacion' is in datetime format\n",
    "df['Fecha Colocacion'] = pd.to_datetime(df['Fecha Colocacion'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# Sort by 'Operacion' and then by 'Fecha Cierre' within each 'Operacion'\n",
    "df_sorted = df.sort_values(by=['Operacion', 'Fecha Cierre'])\n",
    "\n",
    "# Split the data into two DataFrames based on 'Fecha Colocacion' months\n",
    "training_split = df_sorted[df_sorted['Fecha Colocacion'].dt.month <= 9]\n",
    "test_split = df_sorted[df_sorted['Fecha Colocacion'].dt.month >= 10]\n",
    "\n",
    "# Save the sorted DataFrame to new CSV files\n",
    "training_set = '/Users/fabrizioferrari/Desktop/final boss/tlon/Training_Set.csv'\n",
    "test_set = '/Users/fabrizioferrari/Desktop/final boss/tlon/Test_Set.csv'\n",
    "training_split.to_csv(training_set, index=False)\n",
    "test_split.to_csv(test_set, index=False)\n",
    "\n",
    "print(f\"Data has been sorted and saved to {training_set} and {test_set}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/k7tj7j8j0z1_ry92lnh0blg00000gn/T/ipykernel_9060/3718314681.py:7: DtypeWarning: Columns (60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with 'Mora Final', 'Pagare', 'Mora Final %', and 'Atraso' columns saved to /Users/fabrizioferrari/Desktop/final boss/tlon/Test_Set_Columnas.csv\n"
     ]
    }
   ],
   "source": [
    "#test set completo con columnas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/fabrizioferrari/Desktop/final boss/tlon/Test_Set.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure 'Fecha Cierre' is in datetime format\n",
    "df['Fecha Cierre'] = pd.to_datetime(df['Fecha Cierre'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "# Standardize 'Fecha Venta' column: replace typical non-null representations with NaN\n",
    "df['Fecha Venta'].replace(['None', 'N/A', '', 'nan'], pd.NaT, inplace=True)\n",
    "\n",
    "# Convert 'Fecha Venta' to datetime, setting errors='coerce' to handle any remaining non-datetime entries\n",
    "df['Fecha Venta'] = pd.to_datetime(df['Fecha Venta'], errors='coerce')\n",
    "\n",
    "# Initialize dictionaries to store 'Mora Final' and 'Atraso' columns for each 'Operacion'\n",
    "mora_final_dict = {}\n",
    "atraso_dict = {'Atraso30': {}, 'Atraso60': {}, 'Atraso90': {}, 'Atraso120': {}, 'Atraso150': {}, 'Atraso180': {}}\n",
    "\n",
    "for operacion, group in df.groupby('Operacion'):\n",
    "    # Determine if the loan was sold\n",
    "    sold = group['Fecha Venta'].notna().any()\n",
    "    estado_operacion_10 = (group['ESTADO_OPERACION'] == 10).any()\n",
    "    estado_operacion_7 = (group['ESTADO_OPERACION'] == 7).any()\n",
    "    closest_to_present = group.loc[group['Fecha Cierre'].idxmax()]\n",
    "    moroso = closest_to_present['Atraso'] > 30\n",
    "\n",
    "    if not sold and estado_operacion_10:\n",
    "        mora_final = 0\n",
    "    elif estado_operacion_7 and not moroso:\n",
    "        mora_final = 0\n",
    "    elif estado_operacion_7 and moroso:\n",
    "        # Calculate the Mora Final\n",
    "        min_cuotas_pend = group[group['CUOTAS_PEND'] > 0]['CUOTAS_PEND'].min()\n",
    "        valor_cuota = group['Valor Cuota'].iloc[0]\n",
    "        mora_final_antes_de_venta = min_cuotas_pend * valor_cuota\n",
    "        mora_final = mora_final_antes_de_venta * 0.5\n",
    "    else:\n",
    "        # Calculate the Mora Final\n",
    "        min_cuotas_pend = group[group['CUOTAS_PEND'] > 0]['CUOTAS_PEND'].min()\n",
    "        valor_cuota = group['Valor Cuota'].iloc[0]\n",
    "        mora_final_antes_de_venta = min_cuotas_pend * valor_cuota\n",
    "        mora_final = mora_final_antes_de_venta * 0.82\n",
    "\n",
    "    # Store the 'Mora Final' for each 'Operacion'\n",
    "    mora_final_dict[operacion] = mora_final\n",
    "\n",
    "    # Determine 'Atraso' levels for each 'Operacion'\n",
    "    atraso_dict['Atraso30'][operacion] = int(group['Atraso'].max() > 30)\n",
    "    atraso_dict['Atraso60'][operacion] = int(group['Atraso'].max() > 60)\n",
    "    atraso_dict['Atraso90'][operacion] = int(group['Atraso'].max() > 90)\n",
    "    atraso_dict['Atraso120'][operacion] = int(group['Atraso'].max() > 120)\n",
    "    atraso_dict['Atraso150'][operacion] = int(group['Atraso'].max() > 150)\n",
    "    atraso_dict['Atraso180'][operacion] = int(group['Atraso'].max() > 180)\n",
    "\n",
    "# Add the new columns to the original DataFrame\n",
    "df['Mora Final'] = df['Operacion'].map(mora_final_dict)\n",
    "df['Pagare'] = df['Cant. Cuotas'] * df['Valor Cuota']\n",
    "df['Mora Final %'] = df.apply(lambda row: 0 if row['Mora Final'] == 0 else row['Mora Final'] / row['Pagare'], axis=1)\n",
    "df['Atraso30'] = df['Operacion'].map(atraso_dict['Atraso30'])\n",
    "df['Atraso60'] = df['Operacion'].map(atraso_dict['Atraso60'])\n",
    "df['Atraso90'] = df['Operacion'].map(atraso_dict['Atraso90'])\n",
    "df['Atraso120'] = df['Operacion'].map(atraso_dict['Atraso120'])\n",
    "df['Atraso150'] = df['Operacion'].map(atraso_dict['Atraso150'])\n",
    "df['Atraso180'] = df['Operacion'].map(atraso_dict['Atraso180'])\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "output_file_path = '/Users/fabrizioferrari/Desktop/final boss/tlon/Test_Set_Columnas.csv'\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data with 'Mora Final', 'Pagare', 'Mora Final %', and 'Atraso' columns saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/k7tj7j8j0z1_ry92lnh0blg00000gn/T/ipykernel_9060/674678322.py:84: DtypeWarning: Columns (17,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with 'Mora Final', 'Pagare', 'Mora Final %', 'Mora Final % Anualizada', 'Rentabilidad', 'Rentabilidad Anualizada', 'Atraso30', 'Atraso60', 'Atraso90', 'Atraso120', 'Atraso150', and 'Atraso180' saved to /Users/fabrizioferrari/Desktop/final boss/tlon/Training_Set_Columnas_Condensed.csv\n"
     ]
    }
   ],
   "source": [
    "#training set condensado con columnas vvvvvvvvvvvv\n",
    "\n",
    "'''import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/fabrizioferrari/Desktop/final boss/tlon/Training_Set.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure 'Fecha Cierre' is in datetime format\n",
    "df['Fecha Cierre'] = pd.to_datetime(df['Fecha Cierre'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "# Standardize 'Fecha Venta' column: replace typical non-null representations with NaN\n",
    "df['Fecha Venta'].replace(['None', 'N/A', '', 'nan'], pd.NaT, inplace=True)\n",
    "\n",
    "# Convert 'Fecha Venta' to datetime, setting errors='coerce' to handle any remaining non-datetime entries\n",
    "df['Fecha Venta'] = pd.to_datetime(df['Fecha Venta'], errors='coerce')\n",
    "\n",
    "# Initialize dictionaries to store 'Mora Final' and 'Atraso' columns for each 'Operacion'\n",
    "mora_final_dict = {}\n",
    "atraso_dict = {'Atraso30': {}, 'Atraso60': {}, 'Atraso90': {}, 'Atraso120': {}, 'Atraso150': {}, 'Atraso180': {}}\n",
    "\n",
    "for operacion, group in df.groupby('Operacion'):\n",
    "    # Determine if the loan was sold\n",
    "    sold = group['Fecha Venta'].notna().any()\n",
    "    estado_operacion_10 = (group['ESTADO_OPERACION'] == 10).any()\n",
    "    estado_operacion_7 = (group['ESTADO_OPERACION'] == 7).any()\n",
    "    closest_to_present = group.loc[group['Fecha Cierre'].idxmax()]\n",
    "    moroso = closest_to_present['Atraso'] > 30\n",
    "\n",
    "    if not sold and estado_operacion_10:\n",
    "        mora_final = 0\n",
    "    elif estado_operacion_7 and not moroso:\n",
    "        mora_final = 0\n",
    "    elif estado_operacion_7 and moroso:\n",
    "        # Calculate the Mora Final\n",
    "        min_cuotas_pend = group[group['CUOTAS_PEND'] > 0]['CUOTAS_PEND'].min()\n",
    "        valor_cuota = group['Valor Cuota'].iloc[0]\n",
    "        mora_final_antes_de_venta = min_cuotas_pend * valor_cuota\n",
    "        mora_final = mora_final_antes_de_venta * 0.5\n",
    "    else:\n",
    "        # Calculate the Mora Final\n",
    "        min_cuotas_pend = group[group['CUOTAS_PEND'] > 0]['CUOTAS_PEND'].min()\n",
    "        valor_cuota = group['Valor Cuota'].iloc[0]\n",
    "        mora_final_antes_de_venta = min_cuotas_pend * valor_cuota\n",
    "        mora_final = mora_final_antes_de_venta * 0.82\n",
    "\n",
    "    # Store the 'Mora Final' for each 'Operacion'\n",
    "    mora_final_dict[operacion] = mora_final\n",
    "\n",
    "    # Determine 'Atraso' levels for each 'Operacion'\n",
    "    atraso_dict['Atraso30'][operacion] = int(group['Atraso'].max() > 30)\n",
    "    atraso_dict['Atraso60'][operacion] = int(group['Atraso'].max() > 60)\n",
    "    atraso_dict['Atraso90'][operacion] = int(group['Atraso'].max() > 90)\n",
    "    atraso_dict['Atraso120'][operacion] = int(group['Atraso'].max() > 120)\n",
    "    atraso_dict['Atraso150'][operacion] = int(group['Atraso'].max() > 150)\n",
    "    atraso_dict['Atraso180'][operacion] = int(group['Atraso'].max() > 180)\n",
    "\n",
    "# Add the new columns to the original DataFrame\n",
    "df['Mora Final'] = df['Operacion'].map(mora_final_dict)\n",
    "df['Pagare'] = df['Cant. Cuotas'] * df['Valor Cuota']\n",
    "df['Mora Final %'] = df.apply(lambda row: 0 if row['Mora Final'] == 0 else row['Mora Final'] / row['Pagare'], axis=1)\n",
    "df['Atraso30'] = df['Operacion'].map(atraso_dict['Atraso30'])\n",
    "df['Atraso60'] = df['Operacion'].map(atraso_dict['Atraso60'])\n",
    "df['Atraso90'] = df['Operacion'].map(atraso_dict['Atraso90'])\n",
    "df['Atraso120'] = df['Operacion'].map(atraso_dict['Atraso120'])\n",
    "df['Atraso150'] = df['Operacion'].map(atraso_dict['Atraso150'])\n",
    "df['Atraso180'] = df['Operacion'].map(atraso_dict['Atraso180'])\n",
    "\n",
    "# Condense the DataFrame by keeping only the first row of each 'Operacion'\n",
    "df_condensed = df.drop_duplicates(subset='Operacion', keep='first')\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "output_file_path = '/Users/fabrizioferrari/Desktop/final boss/tlon/Training_Set_Columnas_Condensed.csv'\n",
    "df_condensed.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data with 'Mora Final', 'Pagare', 'Mora Final %', 'Atraso30', 'Atraso60', 'Atraso90', 'Atraso120', 'Atraso150', and 'Atraso180' saved to {output_file_path}\")'''\n",
    "#training set con mora y rentabilidad anualizada\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/fabrizioferrari/Desktop/final boss/tlon/Training_Set.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure 'Fecha Cierre' is in datetime format\n",
    "df['Fecha Cierre'] = pd.to_datetime(df['Fecha Cierre'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "# Standardize 'Fecha Venta' column: replace typical non-null representations with NaN\n",
    "df['Fecha Venta'].replace(['None', 'N/A', '', 'nan'], pd.NaT, inplace=True)\n",
    "\n",
    "# Convert 'Fecha Venta' to datetime, setting errors='coerce' to handle any remaining non-datetime entries\n",
    "df['Fecha Venta'] = pd.to_datetime(df['Fecha Venta'], errors='coerce')\n",
    "\n",
    "# Initialize dictionaries to store 'Mora Final' and 'Atraso' columns for each 'Operacion'\n",
    "mora_final_dict = {}\n",
    "atraso_dict = {'Atraso30': {}, 'Atraso60': {}, 'Atraso90': {}, 'Atraso120': {}, 'Atraso150': {}, 'Atraso180': {}}\n",
    "\n",
    "for operacion, group in df.groupby('Operacion'):\n",
    "    # Determine if the loan was sold\n",
    "    sold = group['Fecha Venta'].notna().any()\n",
    "    estado_operacion_10 = (group['ESTADO_OPERACION'] == 10).any()\n",
    "    estado_operacion_7 = (group['ESTADO_OPERACION'] == 7).any()\n",
    "    closest_to_present = group.loc[group['Fecha Cierre'].idxmax()]\n",
    "    moroso = closest_to_present['Atraso'] > 30\n",
    "\n",
    "    if not sold and estado_operacion_10:\n",
    "        mora_final = 0\n",
    "    elif estado_operacion_7 and not moroso:\n",
    "        mora_final = 0\n",
    "    elif estado_operacion_7 and moroso:\n",
    "        # Calculate the Mora Final\n",
    "        min_cuotas_pend = group[group['CUOTAS_PEND'] > 0]['CUOTAS_PEND'].min()\n",
    "        valor_cuota = group['Valor Cuota'].iloc[0]\n",
    "        mora_final_antes_de_venta = min_cuotas_pend * valor_cuota\n",
    "        mora_final = mora_final_antes_de_venta * 0.5\n",
    "    else:\n",
    "        # Calculate the Mora Final\n",
    "        min_cuotas_pend = group[group['CUOTAS_PEND'] > 0]['CUOTAS_PEND'].min()\n",
    "        valor_cuota = group['Valor Cuota'].iloc[0]\n",
    "        mora_final_antes_de_venta = min_cuotas_pend * valor_cuota\n",
    "        mora_final = mora_final_antes_de_venta * 0.82\n",
    "\n",
    "    # Store the 'Mora Final' for each 'Operacion'\n",
    "    mora_final_dict[operacion] = mora_final\n",
    "\n",
    "    # Determine 'Atraso' levels for each 'Operacion'\n",
    "    atraso_dict['Atraso30'][operacion] = int(group['Atraso'].max() > 30)\n",
    "    atraso_dict['Atraso60'][operacion] = int(group['Atraso'].max() > 60)\n",
    "    atraso_dict['Atraso90'][operacion] = int(group['Atraso'].max() > 90)\n",
    "    atraso_dict['Atraso120'][operacion] = int(group['Atraso'].max() > 120)\n",
    "    atraso_dict['Atraso150'][operacion] = int(group['Atraso'].max() > 150)\n",
    "    atraso_dict['Atraso180'][operacion] = int(group['Atraso'].max() > 180)\n",
    "\n",
    "# Add the new columns to the original DataFrame\n",
    "df['Mora Final'] = df['Operacion'].map(mora_final_dict)\n",
    "df['Pagare'] = df['Cant. Cuotas'] * df['Valor Cuota']\n",
    "df['Mora Final %'] = df.apply(lambda row: 0 if row['Mora Final'] == 0 else row['Mora Final'] / row['Pagare'], axis=1)\n",
    "df['Atraso30'] = df['Operacion'].map(atraso_dict['Atraso30'])\n",
    "df['Atraso60'] = df['Operacion'].map(atraso_dict['Atraso60'])\n",
    "df['Atraso90'] = df['Operacion'].map(atraso_dict['Atraso90'])\n",
    "df['Atraso120'] = df['Operacion'].map(atraso_dict['Atraso120'])\n",
    "df['Atraso150'] = df['Operacion'].map(atraso_dict['Atraso150'])\n",
    "df['Atraso180'] = df['Operacion'].map(atraso_dict['Atraso180'])\n",
    "\n",
    "# Calculate 'Mora Final % Anualizada' and 'Rentabilidad Anualizada'\n",
    "def annualize_percentage(value, cant_cuotas):\n",
    "    return value * (12 / cant_cuotas) if cant_cuotas else 0\n",
    "\n",
    "df['Mora Final % Anualizada'] = df.apply(lambda row: annualize_percentage(row['Mora Final %'], row['Cant. Cuotas']), axis=1)\n",
    "\n",
    "df['Rentabilidad'] = df.apply(lambda row: (row['Pagare'] - row['Capital actual'] - row['Mora Final']) / row['Capital actual'] if row['Capital actual'] != 0 else 0, axis=1)\n",
    "df['Rentabilidad Anualizada'] = df.apply(lambda row: annualize_percentage(row['Rentabilidad'], row['Cant. Cuotas']), axis=1)\n",
    "\n",
    "# Condense the DataFrame by keeping only the first row of each 'Operacion'\n",
    "df_condensed = df.drop_duplicates(subset='Operacion', keep='first')\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "output_file_path = '/Users/fabrizioferrari/Desktop/final boss/tlon/Training_Set_Columnas_Condensed.csv'\n",
    "df_condensed.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data with 'Mora Final', 'Pagare', 'Mora Final %', 'Mora Final % Anualizada', 'Rentabilidad', 'Rentabilidad Anualizada', 'Atraso30', 'Atraso60', 'Atraso90', 'Atraso120', 'Atraso150', and 'Atraso180' saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/k7tj7j8j0z1_ry92lnh0blg00000gn/T/ipykernel_9060/3316939386.py:14: DtypeWarning: Columns (60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with selected columns saved to /Users/fabrizioferrari/Desktop/final boss/tlon/Test_Set_Condensed_Stripped.csv\n"
     ]
    }
   ],
   "source": [
    "#generar columnas y condensar:\n",
    "#columnas test set condensado stripped\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Define the columns to retain\n",
    "numerical_cols = [\"Cant. Cuotas\", \"Capital actual\", \"Edad\", \"INGRESO_CLIENTE\", \"Valor Cuota\", \"MONTODESEMBOLSADO\"]\n",
    "categorical_cols = [\"APORTA_IVA\", \"Aportaips\", \"Banca\", \"CALIFICACION_ANTERIOR\", \"CLIENTEFORMAL\",\n",
    "                    \"EMPRESA_PUBLICA1_LAB\", \"EMPRESA_PUBLICA2_LAB\", \"HABILITA_PROD1_BNF\", \"HABILITA_PROD2_BNF\",\n",
    "                    \"MARCA\", \"SEXO\", \"Tipo\", \"Departamento\", \"Sucursaltipo\", \"Medio\", \"Sucursal\", \"Canal\"]\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/fabrizioferrari/Desktop/final boss/tlon/Test_Set.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Combine numerical and categorical columns with 'Operacion' as the key column to retain\n",
    "cols_to_keep = ['Operacion'] + numerical_cols + categorical_cols\n",
    "\n",
    "# Strip the unnecessary columns\n",
    "df_reduced = df[cols_to_keep]\n",
    "\n",
    "# Condense the DataFrame by keeping only the first row of each 'Operacion'\n",
    "df_condensed = df_reduced.drop_duplicates(subset='Operacion', keep='first')\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "output_file_path = '/Users/fabrizioferrari/Desktop/final boss/tlon/Test_Set_Condensed_Stripped.csv'\n",
    "df_condensed.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data with selected columns saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/k7tj7j8j0z1_ry92lnh0blg00000gn/T/ipykernel_9060/1521325947.py:11: DtypeWarning: Columns (17,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv('/Users/fabrizioferrari/Desktop/final boss/tlon/Training_Set_Columnas_Condensed.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6886377\ttotal: 68.1ms\tremaining: 6m 48s\n",
      "100:\tlearn: 0.5023894\ttotal: 743ms\tremaining: 43.4s\n",
      "200:\tlearn: 0.4755238\ttotal: 1.38s\tremaining: 39.9s\n",
      "300:\tlearn: 0.4679680\ttotal: 2.02s\tremaining: 38.3s\n",
      "400:\tlearn: 0.4640642\ttotal: 2.67s\tremaining: 37.3s\n",
      "500:\tlearn: 0.4612628\ttotal: 3.31s\tremaining: 36.4s\n",
      "600:\tlearn: 0.4589991\ttotal: 4s\tremaining: 35.9s\n",
      "700:\tlearn: 0.4571693\ttotal: 4.71s\tremaining: 35.6s\n",
      "800:\tlearn: 0.4555989\ttotal: 5.35s\tremaining: 34.8s\n",
      "900:\tlearn: 0.4542168\ttotal: 6s\tremaining: 34s\n",
      "1000:\tlearn: 0.4530603\ttotal: 6.79s\tremaining: 33.9s\n",
      "1100:\tlearn: 0.4519653\ttotal: 7.49s\tremaining: 33.3s\n",
      "1200:\tlearn: 0.4510071\ttotal: 8.18s\tremaining: 32.7s\n",
      "1300:\tlearn: 0.4500439\ttotal: 8.84s\tremaining: 31.9s\n",
      "1400:\tlearn: 0.4492409\ttotal: 9.55s\tremaining: 31.3s\n",
      "1500:\tlearn: 0.4485155\ttotal: 10.3s\tremaining: 30.8s\n",
      "1600:\tlearn: 0.4478370\ttotal: 11s\tremaining: 30.2s\n",
      "1700:\tlearn: 0.4472414\ttotal: 11.7s\tremaining: 29.6s\n",
      "1800:\tlearn: 0.4466776\ttotal: 12.4s\tremaining: 28.9s\n",
      "1900:\tlearn: 0.4461255\ttotal: 13s\tremaining: 28.1s\n",
      "2000:\tlearn: 0.4456202\ttotal: 13.8s\tremaining: 27.5s\n",
      "2100:\tlearn: 0.4451443\ttotal: 14.4s\tremaining: 26.8s\n",
      "2200:\tlearn: 0.4446995\ttotal: 15.1s\tremaining: 26.1s\n",
      "2300:\tlearn: 0.4442746\ttotal: 15.8s\tremaining: 25.4s\n",
      "2400:\tlearn: 0.4438590\ttotal: 16.4s\tremaining: 24.6s\n",
      "2500:\tlearn: 0.4434871\ttotal: 17.1s\tremaining: 23.9s\n",
      "2600:\tlearn: 0.4431198\ttotal: 17.8s\tremaining: 23.2s\n",
      "2700:\tlearn: 0.4427847\ttotal: 18.4s\tremaining: 22.5s\n",
      "2800:\tlearn: 0.4424511\ttotal: 19.1s\tremaining: 21.8s\n",
      "2900:\tlearn: 0.4421458\ttotal: 19.8s\tremaining: 21.1s\n",
      "3000:\tlearn: 0.4417993\ttotal: 20.4s\tremaining: 20.4s\n",
      "3100:\tlearn: 0.4415297\ttotal: 21.1s\tremaining: 19.7s\n",
      "3200:\tlearn: 0.4412481\ttotal: 21.8s\tremaining: 19.1s\n",
      "3300:\tlearn: 0.4409761\ttotal: 22.5s\tremaining: 18.4s\n",
      "3400:\tlearn: 0.4407133\ttotal: 23.2s\tremaining: 17.7s\n",
      "3500:\tlearn: 0.4404519\ttotal: 23.8s\tremaining: 17s\n",
      "3600:\tlearn: 0.4402156\ttotal: 24.5s\tremaining: 16.3s\n",
      "3700:\tlearn: 0.4399570\ttotal: 25.2s\tremaining: 15.6s\n",
      "3800:\tlearn: 0.4397099\ttotal: 25.8s\tremaining: 14.9s\n",
      "3900:\tlearn: 0.4394842\ttotal: 26.5s\tremaining: 14.3s\n",
      "4000:\tlearn: 0.4392535\ttotal: 27.2s\tremaining: 13.6s\n",
      "4100:\tlearn: 0.4390343\ttotal: 27.8s\tremaining: 12.9s\n",
      "4200:\tlearn: 0.4388213\ttotal: 28.5s\tremaining: 12.2s\n",
      "4300:\tlearn: 0.4386086\ttotal: 29.2s\tremaining: 11.5s\n",
      "4400:\tlearn: 0.4383816\ttotal: 29.9s\tremaining: 10.9s\n",
      "4500:\tlearn: 0.4381777\ttotal: 30.6s\tremaining: 10.2s\n",
      "4600:\tlearn: 0.4379771\ttotal: 31.2s\tremaining: 9.49s\n",
      "4700:\tlearn: 0.4377793\ttotal: 31.9s\tremaining: 8.81s\n",
      "4800:\tlearn: 0.4375789\ttotal: 32.6s\tremaining: 8.14s\n",
      "4900:\tlearn: 0.4374043\ttotal: 33.3s\tremaining: 7.46s\n",
      "5000:\tlearn: 0.4372166\ttotal: 34s\tremaining: 6.78s\n",
      "5100:\tlearn: 0.4370404\ttotal: 34.6s\tremaining: 6.1s\n",
      "5200:\tlearn: 0.4368634\ttotal: 35.3s\tremaining: 5.42s\n",
      "5300:\tlearn: 0.4367056\ttotal: 36s\tremaining: 4.74s\n",
      "5400:\tlearn: 0.4365392\ttotal: 36.7s\tremaining: 4.07s\n",
      "5500:\tlearn: 0.4363758\ttotal: 37.4s\tremaining: 3.39s\n",
      "5600:\tlearn: 0.4362038\ttotal: 38s\tremaining: 2.71s\n",
      "5700:\tlearn: 0.4360530\ttotal: 38.8s\tremaining: 2.03s\n",
      "5800:\tlearn: 0.4358986\ttotal: 39.5s\tremaining: 1.35s\n",
      "5900:\tlearn: 0.4357513\ttotal: 40.2s\tremaining: 674ms\n",
      "5999:\tlearn: 0.4355959\ttotal: 40.8s\tremaining: 0us\n",
      "Confusion Matrix:\n",
      " [[101665   2091]\n",
      " [ 23625   3470]]\n",
      "\n",
      "Confusion Matrix Analysis:\n",
      " {'True Negative': 101665, 'False Positive': 2091, 'False Negative': 23625, 'True Positive': 3470, 'Total': 130851, 'Percent True Negative': 77.69524115215015, 'Percent False Positive': 1.5980007795125755, 'Percent False Negative': 18.05488685604237, 'Percent True Positive': 2.6518712122949, 'Red Flag Percent': 4.249871991807476, 'Accuracy': 80.34711236444507}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import pickle\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('/Users/fabrizioferrari/Desktop/final boss/tlon/Training_Set_Columnas_Condensed.csv')\n",
    "\n",
    "# Define the features and target\n",
    "numerical_cols = [\"Cant. Cuotas\", \"Capital actual\", \"Edad\", \"INGRESO_CLIENTE\", \"Valor Cuota\", \"MONTODESEMBOLSADO\"]\n",
    "categorical_cols = [\"APORTA_IVA\", \"Aportaips\", \"Banca\", \"CALIFICACION_ANTERIOR\", \"CLIENTEFORMAL\",\n",
    "                    \"EMPRESA_PUBLICA1_LAB\", \"EMPRESA_PUBLICA2_LAB\", \"HABILITA_PROD1_BNF\", \"HABILITA_PROD2_BNF\",\n",
    "                    \"MARCA\", \"SEXO\", \"Tipo\", \"Departamento\", \"Sucursaltipo\", \"Medio\", \"Sucursal\", \"Canal\"]\n",
    "target_col = 'Mora Final %'\n",
    "\n",
    "# Define the threshold for binarizing the target\n",
    "threshold = 0.05  # Set this to the desired threshold\n",
    "\n",
    "# Binarize the target based on the threshold\n",
    "data[target_col] = (data[target_col] > threshold).astype(int)\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Define the model with CatBoostClassifier and hyperparameters\n",
    "model = CatBoostClassifier(\n",
    "    iterations=6000,     # Number of boosting iterations\n",
    "    learning_rate=0.01, \n",
    "    l2_leaf_reg=3,# Learning rate\n",
    "    depth=3,             # Depth of the tree\n",
    "    verbose=100          # Verbosity of the training process\n",
    ")\n",
    "\n",
    "# Create and train the pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                           ('classifier', model)])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(data.drop(columns=[target_col]), data[target_col])\n",
    "\n",
    "# Save the model\n",
    "with open('Tlön_Negofin.pkl', 'wb') as f:\n",
    "    pickle.dump(pipeline, f)\n",
    "\n",
    "# Predictions for analysis\n",
    "preds = pipeline.predict(data.drop(columns=[target_col]))\n",
    "conf_matrix = confusion_matrix(data[target_col], preds)\n",
    "accuracy = accuracy_score(data[target_col], preds)\n",
    "total_rows = len(data)\n",
    "\n",
    "# Confusion matrix analysis\n",
    "tn, fp, fn, tp = conf_matrix.ravel()\n",
    "conf_matrix_analysis = {\n",
    "    \"True Negative\": tn,\n",
    "    \"False Positive\": fp,\n",
    "    \"False Negative\": fn,\n",
    "    \"True Positive\": tp,\n",
    "    \"Total\": total_rows,\n",
    "    \"Percent True Negative\": tn / total_rows * 100,\n",
    "    \"Percent False Positive\": fp / total_rows * 100,\n",
    "    \"Percent False Negative\": fn / total_rows * 100,\n",
    "    \"Percent True Positive\": tp / total_rows * 100,\n",
    "    \"Red Flag Percent\": (fp + tp) / total_rows * 100,\n",
    "    \"Accuracy\": accuracy * 100\n",
    "}\n",
    "\n",
    "# Output analysis\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "print(\"\\nConfusion Matrix Analysis:\\n\", conf_matrix_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to /Users/fabrizioferrari/Desktop/final boss/tlon/Resultados.csv\n"
     ]
    }
   ],
   "source": [
    "#code que hace load el pickle file, hace run el modelo con test set condensado stripped y hace output un csv de solo la operacion y score\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the pre-trained model\n",
    "model_file_path = 'Tlön_Negofin.pkl'\n",
    "with open(model_file_path, 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Load the test set data\n",
    "test_data_file_path = '/Users/fabrizioferrari/Desktop/final boss/tlon/Test_Set_Condensed_Stripped.csv'\n",
    "test_data = pd.read_csv(test_data_file_path)\n",
    "\n",
    "# Assuming 'Operacion' is a unique identifier in the test set\n",
    "operacion_col = test_data['Operacion']\n",
    "\n",
    "# Retain 'Cant. Cuotas' for threshold calculation\n",
    "cant_cuotas_col = test_data['Cant. Cuotas']\n",
    "\n",
    "# Predict the probability of the positive class using the loaded model\n",
    "probabilities = model.predict_proba(test_data)[:, 1]\n",
    "\n",
    "## Define the dynamic threshold function lvl 1\n",
    "#def calculate_threshold(cant_cuotas):\n",
    "#    if cant_cuotas <= 12:\n",
    "#        return 0.324\n",
    "#    elif cant_cuotas <= 18:\n",
    "#        return 0.53\n",
    "#    elif cant_cuotas <= 24:\n",
    "#        return 0.69\n",
    "#    else:\n",
    "#        return 0.69\n",
    "\n",
    "\n",
    "## Define the dynamic threshold function lvl 2\n",
    "#def calculate_threshold(cant_cuotas):\n",
    "#    if cant_cuotas <= 12:\n",
    "#        return 0.21\n",
    "#    elif cant_cuotas <= 18:\n",
    "#        return 0.385\n",
    "#    elif cant_cuotas <= 24:\n",
    "#        return 0.603\n",
    "#    else:\n",
    "#        return 0.603\n",
    "\n",
    "# Define the dynamic threshold function lvl 3\n",
    "def calculate_threshold(cant_cuotas):\n",
    "    if cant_cuotas <= 12:\n",
    "        return 0.16\n",
    "    elif cant_cuotas <= 18:\n",
    "        return 0.31\n",
    "    elif cant_cuotas <= 24:\n",
    "        return 0.55\n",
    "    else:\n",
    "        return 0.55\n",
    "# Apply the dynamic threshold to determine the final predictions\n",
    "thresholds = cant_cuotas_col.apply(calculate_threshold)\n",
    "predictions = (probabilities >= thresholds).astype(int)\n",
    "\n",
    "# Prepare the output DataFrame\n",
    "output_df = pd.DataFrame({\n",
    "    'Operacion': operacion_col,\n",
    "    'Resultado': predictions\n",
    "})\n",
    "\n",
    "# Save the output to a new CSV file\n",
    "output_file_path = '/Users/fabrizioferrari/Desktop/final boss/tlon/Resultados.csv'\n",
    "output_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to /Users/fabrizioferrari/Desktop/final boss/tlon/Resultados.csv\n"
     ]
    }
   ],
   "source": [
    "#########################HJHHJHHJHJHJH\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the pre-trained model\n",
    "model_file_path = 'Tlön_Negofin.pkl'\n",
    "with open(model_file_path, 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Load the test set data\n",
    "test_data_file_path = '/Users/fabrizioferrari/Desktop/final boss/tlon/Test_Set_Condensed_Stripped.csv'\n",
    "test_data = pd.read_csv(test_data_file_path)\n",
    "\n",
    "# Assuming 'Operacion' is a unique identifier in the test set\n",
    "operacion_col = test_data['Operacion']\n",
    "\n",
    "# Predict the probability of the positive class using the loaded model\n",
    "probabilities = model.predict_proba(test_data)[:, 1]\n",
    "\n",
    "# Scale probabilities to a score from 1 to 1000\n",
    "scores = 1000 - (probabilities * 1000).astype(int)\n",
    "\n",
    "# Prepare the output DataFrame    ######################## cambiar ########ASGASGSDFGSDFGHSDFHS####################\n",
    "\n",
    "\n",
    "\n",
    "#    rentabilidad bruta * (1-mora) = rentabilidad esperada anualizada ^ (cant cuo/12)\n",
    "    \n",
    "output_df = pd.DataFrame({\n",
    "    'Operacion': operacion_col,\n",
    "    'Resultado': scores\n",
    "})\n",
    "\n",
    "# Save the output to a new CSV file\n",
    "output_file_path = '/Users/fabrizioferrari/Desktop/final boss/tlon/Resultados.csv'\n",
    "output_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Predictions saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/k7tj7j8j0z1_ry92lnh0blg00000gn/T/ipykernel_9060/2492625917.py:11: DtypeWarning: Columns (60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df2 = pd.read_csv(file_path2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns from the first CSV stitched to the second CSV and saved to /Users/fabrizioferrari/Desktop/final boss/tlon/Test_Set_Columnas_Resultados.csv\n"
     ]
    }
   ],
   "source": [
    "#hace stitch el csv de solo operacion y score con el test set complete sorted\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the first CSV file (source of columns to add)\n",
    "file_path1 = '/Users/fabrizioferrari/Desktop/final boss/tlon/Resultados.csv'\n",
    "df1 = pd.read_csv(file_path1)\n",
    "\n",
    "# Load the second CSV file (destination CSV where columns will be added)\n",
    "file_path2 = '/Users/fabrizioferrari/Desktop/final boss/tlon/Test_Set_Columnas.csv'\n",
    "df2 = pd.read_csv(file_path2)\n",
    "\n",
    "# List of columns to stitch from df1 to df2\n",
    "columns_to_stitch = ['Resultado']  # Replace with actual column names\n",
    "\n",
    "# Ensure 'Operacion' is present in both DataFrames\n",
    "if 'Operacion' not in df1.columns or 'Operacion' not in df2.columns:\n",
    "    raise ValueError(\"'Operacion' column must be present in both CSV files.\")\n",
    "\n",
    "# Merge df1 with df2 on the 'Operacion' column, keeping all rows from df2\n",
    "df_merged = pd.merge(df2, df1[['Operacion'] + columns_to_stitch], on='Operacion', how='left')\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "output_file_path = '/Users/fabrizioferrari/Desktop/final boss/tlon/Test_Set_Columnas_Resultados.csv'\n",
    "df_merged.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Columns from the first CSV stitched to the second CSV and saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/k7tj7j8j0z1_ry92lnh0blg00000gn/T/ipykernel_9060/4043120300.py:5: DtypeWarning: Columns (60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Metrics:\n",
      "Mora Final %: 13.00%\n",
      "Rentabilidad: 28.00%\n",
      "Rentabilidad Descontada: 25.19%\n",
      "Percent of Operaciones with Resultado = 1: 0.00%\n",
      "\n",
      "Metrics for Resultado = 1:\n",
      "Mora Final %: 0.00%\n",
      "Rentabilidad: 0.00%\n",
      "Rentabilidad Descontada: nan%\n",
      "\n",
      "Metrics for Resultado = 0:\n",
      "Mora Final %: 0.00%\n",
      "Rentabilidad: 0.00%\n",
      "Rentabilidad Descontada: nan%\n",
      "\n",
      "Metrics for Cant. Cuotas = 12:\n",
      "Mora Final %: 9.01%\n",
      "Rentabilidad: 27.56%\n",
      "Rentabilidad Descontada: 27.56%\n",
      "\n",
      "Metrics for Cant. Cuotas = 18:\n",
      "Mora Final %: 15.60%\n",
      "Rentabilidad: 31.09%\n",
      "Rentabilidad Descontada: 20.72%\n",
      "\n",
      "Metrics for Cant. Cuotas = 10:\n",
      "Mora Final %: 8.15%\n",
      "Rentabilidad: 12.41%\n",
      "Rentabilidad Descontada: 14.90%\n",
      "\n",
      "Metrics for Cant. Cuotas = 24:\n",
      "Mora Final %: 19.38%\n",
      "Rentabilidad: 47.26%\n",
      "Rentabilidad Descontada: 23.63%\n",
      "\n",
      "Metrics for Cant. Cuotas = 6:\n",
      "Mora Final %: 6.23%\n",
      "Rentabilidad: 6.36%\n",
      "Rentabilidad Descontada: 12.73%\n",
      "\n",
      "Metrics for Cant. Cuotas = 8:\n",
      "Mora Final %: 8.28%\n",
      "Rentabilidad: 8.33%\n",
      "Rentabilidad Descontada: 12.49%\n",
      "\n",
      "Metrics for Cant. Cuotas = 15:\n",
      "Mora Final %: 10.81%\n",
      "Rentabilidad: 27.42%\n",
      "Rentabilidad Descontada: 21.93%\n",
      "\n",
      "Metrics for Cant. Cuotas = 20:\n",
      "Mora Final %: 18.19%\n",
      "Rentabilidad: 33.33%\n",
      "Rentabilidad Descontada: 20.00%\n",
      "\n",
      "Metrics for Cant. Cuotas = 13:\n",
      "Mora Final %: 8.93%\n",
      "Rentabilidad: 20.85%\n",
      "Rentabilidad Descontada: 19.25%\n",
      "\n",
      "Metrics for Cant. Cuotas = 7:\n",
      "Mora Final %: 9.99%\n",
      "Rentabilidad: 6.56%\n",
      "Rentabilidad Descontada: 11.25%\n",
      "\n",
      "Metrics for Cant. Cuotas = 22:\n",
      "Mora Final %: 18.38%\n",
      "Rentabilidad: 50.50%\n",
      "Rentabilidad Descontada: 27.55%\n",
      "\n",
      "Metrics for Cant. Cuotas = 9:\n",
      "Mora Final %: 20.83%\n",
      "Rentabilidad: -2.74%\n",
      "Rentabilidad Descontada: -3.66%\n",
      "\n",
      "Metrics for Cant. Cuotas = 14:\n",
      "Mora Final %: 15.08%\n",
      "Rentabilidad: 16.48%\n",
      "Rentabilidad Descontada: 14.13%\n",
      "\n",
      "Metrics for Cant. Cuotas = 11:\n",
      "Mora Final %: 13.96%\n",
      "Rentabilidad: 9.23%\n",
      "Rentabilidad Descontada: 10.06%\n",
      "\n",
      "Metrics for Cant. Cuotas = 1:\n",
      "Mora Final %: 4.80%\n",
      "Rentabilidad: -1.34%\n",
      "Rentabilidad Descontada: -16.09%\n",
      "\n",
      "Metrics for Cant. Cuotas = 17:\n",
      "Mora Final %: 22.90%\n",
      "Rentabilidad: 16.23%\n",
      "Rentabilidad Descontada: 11.46%\n",
      "\n",
      "Metrics for Cant. Cuotas = 19:\n",
      "Mora Final %: 3.49%\n",
      "Rentabilidad: 58.80%\n",
      "Rentabilidad Descontada: 37.14%\n",
      "\n",
      "Metrics for Cant. Cuotas = 16:\n",
      "Mora Final %: 18.40%\n",
      "Rentabilidad: 20.97%\n",
      "Rentabilidad Descontada: 15.73%\n",
      "\n",
      "Metrics for Cant. Cuotas = 23:\n",
      "Mora Final %: 12.68%\n",
      "Rentabilidad: 55.57%\n",
      "Rentabilidad Descontada: 28.99%\n",
      "\n",
      "Metrics for Cant. Cuotas = 4:\n",
      "Mora Final %: 0.00%\n",
      "Rentabilidad: -88.46%\n",
      "Rentabilidad Descontada: -265.37%\n",
      "\n",
      "Metrics for Cant. Cuotas = 2:\n",
      "Mora Final %: 0.00%\n",
      "Rentabilidad: -3.16%\n",
      "Rentabilidad Descontada: -18.93%\n",
      "\n",
      "Metrics for Cant. Cuotas = 21:\n",
      "Mora Final %: 13.92%\n",
      "Rentabilidad: 47.43%\n",
      "Rentabilidad Descontada: 27.10%\n",
      "\n",
      "Metrics for Cant. Cuotas = 3:\n",
      "Mora Final %: 0.00%\n",
      "Rentabilidad: 12.27%\n",
      "Rentabilidad Descontada: 49.07%\n",
      "\n",
      "Metrics for Cant. Cuotas = 36:\n",
      "Mora Final %: 0.00%\n",
      "Rentabilidad: 42.01%\n",
      "Rentabilidad Descontada: 14.00%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "file_path = '/Users/fabrizioferrari/Desktop/final boss/tlon/Test_Set_Columnas_Resultados.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "#data = data[data['Cant. Cuotas'] <= 24 ]\n",
    "#data = data[data['Cant. Cuotas'] > 18 ]\n",
    "\n",
    "\n",
    "# Aggregate data by 'Operacion'\n",
    "aggregated_data = data.groupby('Operacion').agg({\n",
    "    'Mora Final': 'sum',\n",
    "    'Pagare': 'sum',\n",
    "    'Capital actual': 'sum',\n",
    "    'Resultado': 'first',  # Assuming 'Resultado' is consistent across rows for the same 'Operacion'\n",
    "    'Cant. Cuotas': 'first'  # Assuming 'Cant. Cuotas' is consistent across rows for the same 'Operacion'\n",
    "}).reset_index()\n",
    "\n",
    "# Function to calculate Mora Final %, Rentabilidad, and Rentabilidad Descontada\n",
    "def calculate_metrics(df):\n",
    "    mora_final_total = df['Mora Final'].sum()\n",
    "    pagare_total = df['Pagare'].sum()\n",
    "    capital_anterior_total = df['Capital actual'].sum()\n",
    "\n",
    "    mora_final_percent = mora_final_total / pagare_total if pagare_total != 0 else 0\n",
    "    rentabilidad = ((pagare_total - capital_anterior_total - mora_final_total) / capital_anterior_total) if capital_anterior_total != 0 else 0\n",
    "\n",
    "    # Adjust Rentabilidad for loan duration to get Rentabilidad Descontada\n",
    "    average_cant_cuotas = df['Cant. Cuotas'].mean()\n",
    "    rentabilidad_descontada = rentabilidad * (12 / average_cant_cuotas) if average_cant_cuotas != 0 else 0\n",
    "\n",
    "    return mora_final_percent, rentabilidad, rentabilidad_descontada\n",
    "\n",
    "# Calculate metrics for the entire dataset\n",
    "total_mora_final_percent, total_rentabilidad, total_rentabilidad_descontada = calculate_metrics(aggregated_data)\n",
    "\n",
    "# Calculate metrics for 'Resultado' = 1\n",
    "data_result_1 = aggregated_data[aggregated_data['Resultado'] == 1]\n",
    "mora_final_percent_1, rentabilidad_1, rentabilidad_descontada_1 = calculate_metrics(data_result_1)\n",
    "\n",
    "# Calculate metrics for 'Resultado' = 0\n",
    "data_result_0 = aggregated_data[aggregated_data['Resultado'] == 0]\n",
    "mora_final_percent_0, rentabilidad_0, rentabilidad_descontada_0 = calculate_metrics(data_result_0)\n",
    "\n",
    "# Calculate the percentage of 'Operaciones' that got 1 in 'Resultado'\n",
    "percent_result_1 = len(data_result_1) / len(aggregated_data) * 100\n",
    "\n",
    "# Print the overall results\n",
    "print(\"Overall Metrics:\")\n",
    "print(f\"Mora Final %: {total_mora_final_percent:.2%}\")\n",
    "print(f\"Rentabilidad: {total_rentabilidad:.2%}\")\n",
    "print(f\"Rentabilidad Descontada: {total_rentabilidad_descontada:.2%}\")\n",
    "print(f\"Percent of Operaciones with Resultado = 1: {percent_result_1:.2f}%\")\n",
    "print(\"\\nMetrics for Resultado = 1:\")\n",
    "print(f\"Mora Final %: {mora_final_percent_1:.2%}\")\n",
    "print(f\"Rentabilidad: {rentabilidad_1:.2%}\")\n",
    "print(f\"Rentabilidad Descontada: {rentabilidad_descontada_1:.2%}\")\n",
    "print(\"\\nMetrics for Resultado = 0:\")\n",
    "print(f\"Mora Final %: {mora_final_percent_0:.2%}\")\n",
    "print(f\"Rentabilidad: {rentabilidad_0:.2%}\")\n",
    "print(f\"Rentabilidad Descontada: {rentabilidad_descontada_0:.2%}\")\n",
    "\n",
    "# Calculate metrics for each unique value of 'Cant. Cuotas'\n",
    "for cuotas in aggregated_data['Cant. Cuotas'].unique():\n",
    "    data_cuotas = aggregated_data[aggregated_data['Cant. Cuotas'] == cuotas]\n",
    "    mora_final_percent_cuotas, rentabilidad_cuotas, rentabilidad_descontada_cuotas = calculate_metrics(data_cuotas)\n",
    "    print(f\"\\nMetrics for Cant. Cuotas = {cuotas}:\")\n",
    "    print(f\"Mora Final %: {mora_final_percent_cuotas:.2%}\")\n",
    "    print(f\"Rentabilidad: {rentabilidad_cuotas:.2%}\")\n",
    "    print(f\"Rentabilidad Descontada: {rentabilidad_descontada_cuotas:.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
