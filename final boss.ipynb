{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import joblib\n",
    "import logging\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/k7tj7j8j0z1_ry92lnh0blg00000gn/T/ipykernel_11626/1215289551.py:5: DtypeWarning: Columns (7,17,56,58,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been sorted and saved to /Users/fabrizioferrari/Desktop/final boss/Training_Set.csv and /Users/fabrizioferrari/Desktop/final boss/Test_Set.csv\n"
     ]
    }
   ],
   "source": [
    "# sort and split\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/fabrizioferrari/Desktop/OG.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure 'Fecha Cierre' is in datetime format\n",
    "df['Fecha Cierre'] = pd.to_datetime(df['Fecha Cierre'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "# Ensure 'Fecha Colocacion' is in datetime format\n",
    "df['Fecha Colocacion'] = pd.to_datetime(df['Fecha Colocacion'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "df = df[df['Score'] != 0]\n",
    "\n",
    "# Sort by 'Operacion' and then by 'Fecha Cierre' within each 'Operacion'\n",
    "df_sorted = df.sort_values(by=['Operacion', 'Fecha Cierre'])\n",
    "\n",
    "# Split the data into two DataFrames based on 'Fecha Colocacion' months\n",
    "training_split = df_sorted[df_sorted['Fecha Colocacion'].dt.month <= 9]\n",
    "test_split = df_sorted[df_sorted['Fecha Colocacion'].dt.month >= 10]\n",
    "\n",
    "# Save the sorted DataFrame to new CSV files\n",
    "training_set = '/Users/fabrizioferrari/Desktop/final boss/Training_Set.csv'\n",
    "test_set = '/Users/fabrizioferrari/Desktop/final boss/Test_Set.csv'\n",
    "training_split.to_csv(training_set, index=False)\n",
    "test_split.to_csv(test_set, index=False)\n",
    "\n",
    "print(f\"Data has been sorted and saved to {training_set} and {test_set}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/k7tj7j8j0z1_ry92lnh0blg00000gn/T/ipykernel_11626/4294853946.py:4: DtypeWarning: Columns (60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with 'Mora Final', 'Pagare', 'Mora Final %', and 'Atraso' columns saved to /Users/fabrizioferrari/Desktop/final boss/Test_Set_Columnas.csv\n"
     ]
    }
   ],
   "source": [
    "#test set completo con columnas\n",
    "# Load the CSV file\n",
    "file_path = '/Users/fabrizioferrari/Desktop/final boss/Test_Set.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure 'Fecha Cierre' is in datetime format\n",
    "df['Fecha Cierre'] = pd.to_datetime(df['Fecha Cierre'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "# Standardize 'Fecha Venta' column: replace typical non-null representations with NaN\n",
    "df['Fecha Venta'].replace(['None', 'N/A', '', 'nan'], pd.NaT, inplace=True)\n",
    "\n",
    "# Convert 'Fecha Venta' to datetime, setting errors='coerce' to handle any remaining non-datetime entries\n",
    "df['Fecha Venta'] = pd.to_datetime(df['Fecha Venta'], errors='coerce')\n",
    "\n",
    "# Initialize dictionaries to store 'Mora Final' and 'Atraso' columns for each 'Operacion'\n",
    "mora_final_dict = {}\n",
    "atraso_dict = {'Atraso30': {}, 'Atraso60': {}, 'Atraso90': {}, 'Atraso120': {}, 'Atraso150': {}, 'Atraso180': {}}\n",
    "\n",
    "for operacion, group in df.groupby('Operacion'):\n",
    "    # Determine if the loan was sold\n",
    "    sold = group['Fecha Venta'].notna().any()\n",
    "    estado_operacion_10 = (group['ESTADO_OPERACION'] == 10).any()\n",
    "    estado_operacion_7 = (group['ESTADO_OPERACION'] == 7).any()\n",
    "    closest_to_present = group.loc[group['Fecha Cierre'].idxmax()]\n",
    "    moroso = closest_to_present['Atraso'] > 30\n",
    "\n",
    "    if not sold and estado_operacion_10:\n",
    "        mora_final = 0\n",
    "    elif estado_operacion_7 and not moroso:\n",
    "        mora_final = 0\n",
    "    elif estado_operacion_7 and moroso:\n",
    "        # Calculate the Mora Final\n",
    "        min_cuotas_pend = group[group['CUOTAS_PEND'] > 0]['CUOTAS_PEND'].min()\n",
    "        valor_cuota = group['Valor Cuota'].iloc[0]\n",
    "        mora_final_antes_de_venta = min_cuotas_pend * valor_cuota\n",
    "        mora_final = mora_final_antes_de_venta * 0.5\n",
    "    else:\n",
    "        # Calculate the Mora Final\n",
    "        min_cuotas_pend = group[group['CUOTAS_PEND'] > 0]['CUOTAS_PEND'].min()\n",
    "        valor_cuota = group['Valor Cuota'].iloc[0]\n",
    "        mora_final_antes_de_venta = min_cuotas_pend * valor_cuota\n",
    "        mora_final = mora_final_antes_de_venta * 0.82\n",
    "\n",
    "    # Store the 'Mora Final' for each 'Operacion'\n",
    "    mora_final_dict[operacion] = mora_final\n",
    "\n",
    "    # Determine 'Atraso' levels for each 'Operacion'\n",
    "    atraso_dict['Atraso30'][operacion] = int(group['Atraso'].max() > 30)\n",
    "    atraso_dict['Atraso60'][operacion] = int(group['Atraso'].max() > 60)\n",
    "    atraso_dict['Atraso90'][operacion] = int(group['Atraso'].max() > 90)\n",
    "    atraso_dict['Atraso120'][operacion] = int(group['Atraso'].max() > 120)\n",
    "    atraso_dict['Atraso150'][operacion] = int(group['Atraso'].max() > 150)\n",
    "    atraso_dict['Atraso180'][operacion] = int(group['Atraso'].max() > 180)\n",
    "\n",
    "# Add the new columns to the original DataFrame\n",
    "df['Mora Final'] = df['Operacion'].map(mora_final_dict)\n",
    "df['Pagare'] = df['Cant. Cuotas'] * df['Valor Cuota']\n",
    "df['Mora Final %'] = df.apply(lambda row: 0 if row['Mora Final'] == 0 else row['Mora Final'] / row['Pagare'], axis=1)\n",
    "df['Atraso30'] = df['Operacion'].map(atraso_dict['Atraso30'])\n",
    "df['Atraso60'] = df['Operacion'].map(atraso_dict['Atraso60'])\n",
    "df['Atraso90'] = df['Operacion'].map(atraso_dict['Atraso90'])\n",
    "df['Atraso120'] = df['Operacion'].map(atraso_dict['Atraso120'])\n",
    "df['Atraso150'] = df['Operacion'].map(atraso_dict['Atraso150'])\n",
    "df['Atraso180'] = df['Operacion'].map(atraso_dict['Atraso180'])\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "output_file_path = '/Users/fabrizioferrari/Desktop/final boss/Test_Set_Columnas.csv'\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data with 'Mora Final', 'Pagare', 'Mora Final %', and 'Atraso' columns saved to {output_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/k7tj7j8j0z1_ry92lnh0blg00000gn/T/ipykernel_11626/3529821944.py:5: DtypeWarning: Columns (17,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with 'Mora Final', 'Pagare', 'Mora Final %', 'Atraso30', 'Atraso60', 'Atraso90', 'Atraso120', 'Atraso150', and 'Atraso180' saved to /Users/fabrizioferrari/Desktop/final boss/Training_Set_Columnas_Condensed.csv\n"
     ]
    }
   ],
   "source": [
    "#training set condensado con columnas\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/fabrizioferrari/Desktop/final boss/Training_Set.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Ensure 'Fecha Cierre' is in datetime format\n",
    "df['Fecha Cierre'] = pd.to_datetime(df['Fecha Cierre'], format='%Y-%m-%d', errors='coerce')\n",
    "\n",
    "# Standardize 'Fecha Venta' column: replace typical non-null representations with NaN\n",
    "df['Fecha Venta'].replace(['None', 'N/A', '', 'nan'], pd.NaT, inplace=True)\n",
    "\n",
    "# Convert 'Fecha Venta' to datetime, setting errors='coerce' to handle any remaining non-datetime entries\n",
    "df['Fecha Venta'] = pd.to_datetime(df['Fecha Venta'], errors='coerce')\n",
    "\n",
    "# Initialize dictionaries to store 'Mora Final' and 'Atraso' columns for each 'Operacion'\n",
    "mora_final_dict = {}\n",
    "atraso_dict = {'Atraso30': {}, 'Atraso60': {}, 'Atraso90': {}, 'Atraso120': {}, 'Atraso150': {}, 'Atraso180': {}}\n",
    "\n",
    "for operacion, group in df.groupby('Operacion'):\n",
    "    # Determine if the loan was sold\n",
    "    sold = group['Fecha Venta'].notna().any()\n",
    "    estado_operacion_10 = (group['ESTADO_OPERACION'] == 10).any()\n",
    "    estado_operacion_7 = (group['ESTADO_OPERACION'] == 7).any()\n",
    "    closest_to_present = group.loc[group['Fecha Cierre'].idxmax()]\n",
    "    moroso = closest_to_present['Atraso'] > 30\n",
    "\n",
    "    if not sold and estado_operacion_10:\n",
    "        mora_final = 0\n",
    "    elif estado_operacion_7 and not moroso:\n",
    "        mora_final = 0\n",
    "    elif estado_operacion_7 and moroso:\n",
    "        # Calculate the Mora Final\n",
    "        min_cuotas_pend = group[group['CUOTAS_PEND'] > 0]['CUOTAS_PEND'].min()\n",
    "        valor_cuota = group['Valor Cuota'].iloc[0]\n",
    "        mora_final_antes_de_venta = min_cuotas_pend * valor_cuota\n",
    "        mora_final = mora_final_antes_de_venta * 0.5\n",
    "    else:\n",
    "        # Calculate the Mora Final\n",
    "        min_cuotas_pend = group[group['CUOTAS_PEND'] > 0]['CUOTAS_PEND'].min()\n",
    "        valor_cuota = group['Valor Cuota'].iloc[0]\n",
    "        mora_final_antes_de_venta = min_cuotas_pend * valor_cuota\n",
    "        mora_final = mora_final_antes_de_venta * 0.82\n",
    "\n",
    "    # Store the 'Mora Final' for each 'Operacion'\n",
    "    mora_final_dict[operacion] = mora_final\n",
    "\n",
    "    # Determine 'Atraso' levels for each 'Operacion'\n",
    "    atraso_dict['Atraso30'][operacion] = int(group['Atraso'].max() > 30)\n",
    "    atraso_dict['Atraso60'][operacion] = int(group['Atraso'].max() > 60)\n",
    "    atraso_dict['Atraso90'][operacion] = int(group['Atraso'].max() > 90)\n",
    "    atraso_dict['Atraso120'][operacion] = int(group['Atraso'].max() > 120)\n",
    "    atraso_dict['Atraso150'][operacion] = int(group['Atraso'].max() > 150)\n",
    "    atraso_dict['Atraso180'][operacion] = int(group['Atraso'].max() > 180)\n",
    "\n",
    "# Add the new columns to the original DataFrame\n",
    "df['Mora Final'] = df['Operacion'].map(mora_final_dict)\n",
    "df['Pagare'] = df['Cant. Cuotas'] * df['Valor Cuota']\n",
    "df['Mora Final %'] = df.apply(lambda row: 0 if row['Mora Final'] == 0 else row['Mora Final'] / row['Pagare'], axis=1)\n",
    "df['Atraso30'] = df['Operacion'].map(atraso_dict['Atraso30'])\n",
    "df['Atraso60'] = df['Operacion'].map(atraso_dict['Atraso60'])\n",
    "df['Atraso90'] = df['Operacion'].map(atraso_dict['Atraso90'])\n",
    "df['Atraso120'] = df['Operacion'].map(atraso_dict['Atraso120'])\n",
    "df['Atraso150'] = df['Operacion'].map(atraso_dict['Atraso150'])\n",
    "df['Atraso180'] = df['Operacion'].map(atraso_dict['Atraso180'])\n",
    "\n",
    "# Condense the DataFrame by keeping only the first row of each 'Operacion'\n",
    "df_condensed = df.drop_duplicates(subset='Operacion', keep='first')\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "output_file_path = '/Users/fabrizioferrari/Desktop/final boss/Training_Set_Columnas_Condensed.csv'\n",
    "df_condensed.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data with 'Mora Final', 'Pagare', 'Mora Final %', 'Atraso30', 'Atraso60', 'Atraso90', 'Atraso120', 'Atraso150', and 'Atraso180' saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6m/k7tj7j8j0z1_ry92lnh0blg00000gn/T/ipykernel_11626/2269864719.py:11: DtypeWarning: Columns (60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with selected columns saved to /Users/fabrizioferrari/Desktop/final boss/Test_Set_Condensed_Stripped.csv\n"
     ]
    }
   ],
   "source": [
    "#generar columnas y condensar:\n",
    "#columnas test set condensado stripped\n",
    "\n",
    "# Define the columns to retain\n",
    "categorical_cols = [ \"Banca\", \"CALIFICACION_ANTERIOR\",  \n",
    "                        \"MARCA\",  \"SEXO\", \"Tipo\", \"Departamento\",  \"Medio\",  \"Canal\"]\n",
    "numerical_cols = [\"Cant. Cuotas\", \"Capital actual\", \"Edad\", \"INGRESO_CLIENTE\", \"Valor Cuota\"]\n",
    "\n",
    "# Load the CSV file\n",
    "file_path = '/Users/fabrizioferrari/Desktop/final boss/Test_Set.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Combine numerical and categorical columns with 'Operacion' as the key column to retain\n",
    "cols_to_keep = ['Operacion'] + numerical_cols + categorical_cols\n",
    "\n",
    "# Strip the unnecessary columns\n",
    "df_reduced = df[cols_to_keep]\n",
    "\n",
    "# Condense the DataFrame by keeping only the first row of each 'Operacion'\n",
    "df_condensed = df_reduced.drop_duplicates(subset='Operacion', keep='first')\n",
    "\n",
    "# Save the modified DataFrame to a new CSV file\n",
    "output_file_path = '/Users/fabrizioferrari/Desktop/final boss/Test_Set_Condensed_Stripped.csv'\n",
    "df_condensed.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Data with selected columns saved to {output_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "def load_data(file_path, delimiter=','):\n",
    "    \"\"\"Load the CSV file with the correct delimiter and strip spaces from column names.\"\"\"\n",
    "    try:\n",
    "        data = pd.read_csv(file_path, delimiter=delimiter)\n",
    "        data.columns = data.columns.str.strip()\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading data from {file_path}: {e}\")\n",
    "        raise\n",
    "\n",
    "def filter_data(data):\n",
    "    \"\"\"Apply filtering conditions on the data.\"\"\"\n",
    "    filtered_data = data[(data['Score'] != 0 )]\n",
    "    filtered_data = filtered_data[filtered_data['SEXO'].isin(['M', 'F'])]\n",
    "    filtered_data = filtered_data[(filtered_data['Edad'] <= 90) & (filtered_data['Edad'] >= 18)]\n",
    "    filtered_data = filtered_data[(filtered_data['INGRESO_CLIENTE'] <= 500000001) & (filtered_data['INGRESO_CLIENTE'] >= 1000000)]\n",
    "    filtered_data = filtered_data[(filtered_data['Cant. Cuotas'] <= 24) & (filtered_data['Cant. Cuotas'] >= 1)]\n",
    "    filtered_data = filtered_data[(filtered_data['Capital actual'] <= 30000000) & (filtered_data['Capital actual'] >= 300000)]\n",
    "    filtered_data = filtered_data[(filtered_data['Valor Cuota'] <= 10000000) & (filtered_data['Valor Cuota'] >= 50000)]\n",
    "    filtered_data = filtered_data[filtered_data['Banca'].isin([240, 420, 130, 471, 421, 470])]\n",
    "    filtered_data = filtered_data[filtered_data['Tipo'].isin([201, 205, 300, 305, 200])]\n",
    "    return filtered_data\n",
    "\n",
    "def drop_columns(data, columns_to_drop):\n",
    "    \"\"\"Drop unnecessary columns from the data.\"\"\"\n",
    "    columns_to_drop = [col for col in columns_to_drop if col in data.columns]\n",
    "    return data.drop(columns=columns_to_drop)\n",
    "\n",
    "def preprocess_data(data, categorical_cols, numerical_cols, target_col):\n",
    "    \"\"\"Encode categorical variables, handle missing values, and scale numerical features.\"\"\"\n",
    "    data_encoded = pd.get_dummies(data, columns=categorical_cols)\n",
    "    \n",
    "    X = data_encoded.drop(columns=[target_col])\n",
    "    y = data_encoded[target_col]\n",
    "    \n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_imputed)\n",
    "    \n",
    "    return X_scaled, y, imputer, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 14:49:34,697 - INFO - Loading data...\n",
      "/var/folders/6m/k7tj7j8j0z1_ry92lnh0blg00000gn/T/ipykernel_11626/56561933.py:3: DtypeWarning: Columns (17,60) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(file_path)\n",
      "2024-07-29 14:49:35,737 - INFO - Columns in the dataset after loading: ['Año de Fecha Cierre', 'Fecha Cierre', 'Fecha Colocacion', 'Analista', 'APORTA_IVA', 'Aportaips', 'Aproblinea', 'Aprobscoring', 'Atraso', 'Banca', 'CALIFICACION', 'CALIFICACION_ANTERIOR', 'Canal', 'Cant. Cuotas', 'Capital actual', 'Capital anterior', 'Capital Venta', 'CIRCUITO_OPE', 'CIUDADLAB', 'CLIENTEFORMAL', 'COBROWALTON', 'COD_EMPRESA1_LAB', 'COD_EMPRESA2_LAB', 'Condicionado', 'Controlscoring', 'CUENTA', 'CUOTAS_PEND', 'CUOTASPAGADAS', 'Departamento', 'Edad', 'EMPRESA_PUBLICA1_LAB', 'EMPRESA_PUBLICA2_LAB', 'EMPRESA1_LAB', 'EMPRESA2_LAB', 'ESTADO_OPERACION', 'Excepcion', 'EXCEPCIONANALISTA', 'EXCEPCIONESTADO', 'EXCEPCIONINSTANCIA', 'EXCEPCIONMOTIVO', 'EXCEPCIONTIPO', 'Faja', 'Fecha Venta', 'FECHA_CANCELACION', 'Franquicia', 'HABILITA_PROD1_BNF', 'HABILITA_PROD2_BNF', 'INGRESO_CLIENTE', 'INTERES_VTA', 'INTERES2', 'IVA_LEY', 'MARCA', 'Medio', 'MONTO_ANTERIOR', 'MONTODESEMBOLSADO', 'OPE_NUEVA', 'OPEPARALELA', 'Operacion', 'OPERACIONIPS', 'PATENTE_COMERCIAL', 'Rechazocarga', 'RUC_EMPRESA1_LAB', 'RUC_EMPRESA2_LAB', 'Saldo Capital', 'Score', 'SCORE_BICSA', 'SCORE_DATALAB', 'SECTOR_ECONOMICO', 'SEXO', 'SITUACION', 'Sucursal', 'Sucursaltipo', 'Supervisor', 'Tipo', 'Tipo_Aprobacion', 'ULTIMO_ATRASO', 'Valor Cuota', 'Vendedor', 'Mora Final', 'Pagare', 'Mora Final %', 'Atraso30', 'Atraso60', 'Atraso90', 'Atraso120', 'Atraso150', 'Atraso180']\n",
      "2024-07-29 14:49:35,738 - INFO - Filtering data...\n",
      "2024-07-29 14:49:35,738 - INFO - Dropping unnecessary columns...\n",
      "2024-07-29 14:49:35,758 - INFO - Columns in the dataset after dropping: ['Banca', 'CALIFICACION_ANTERIOR', 'Canal', 'Cant. Cuotas', 'Capital actual', 'Departamento', 'Edad', 'INGRESO_CLIENTE', 'MARCA', 'Medio', 'SEXO', 'Tipo', 'Valor Cuota', 'Atraso180']\n",
      "2024-07-29 14:49:35,759 - INFO - Preprocessing data...\n",
      "2024-07-29 14:49:36,235 - INFO - Training the model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6676399\ttotal: 9.06ms\tremaining: 3.61s\n",
      "1:\tlearn: 0.6447410\ttotal: 17.5ms\tremaining: 3.49s\n",
      "2:\tlearn: 0.6258807\ttotal: 26.4ms\tremaining: 3.5s\n",
      "3:\tlearn: 0.6086107\ttotal: 36.2ms\tremaining: 3.58s\n",
      "4:\tlearn: 0.5944453\ttotal: 58.1ms\tremaining: 4.59s\n",
      "5:\tlearn: 0.5808474\ttotal: 68ms\tremaining: 4.47s\n",
      "6:\tlearn: 0.5696779\ttotal: 77.7ms\tremaining: 4.36s\n",
      "7:\tlearn: 0.5598600\ttotal: 86.9ms\tremaining: 4.26s\n",
      "8:\tlearn: 0.5509337\ttotal: 96.3ms\tremaining: 4.18s\n",
      "9:\tlearn: 0.5431479\ttotal: 106ms\tremaining: 4.12s\n",
      "10:\tlearn: 0.5365304\ttotal: 115ms\tremaining: 4.06s\n",
      "11:\tlearn: 0.5304087\ttotal: 125ms\tremaining: 4.03s\n",
      "12:\tlearn: 0.5250058\ttotal: 133ms\tremaining: 3.96s\n",
      "13:\tlearn: 0.5199489\ttotal: 142ms\tremaining: 3.92s\n",
      "14:\tlearn: 0.5157679\ttotal: 152ms\tremaining: 3.89s\n",
      "15:\tlearn: 0.5121518\ttotal: 161ms\tremaining: 3.86s\n",
      "16:\tlearn: 0.5088301\ttotal: 169ms\tremaining: 3.81s\n",
      "17:\tlearn: 0.5060545\ttotal: 178ms\tremaining: 3.78s\n",
      "18:\tlearn: 0.5033655\ttotal: 186ms\tremaining: 3.74s\n",
      "19:\tlearn: 0.5013809\ttotal: 195ms\tremaining: 3.71s\n",
      "20:\tlearn: 0.4993409\ttotal: 205ms\tremaining: 3.7s\n",
      "21:\tlearn: 0.4976190\ttotal: 215ms\tremaining: 3.69s\n",
      "22:\tlearn: 0.4959348\ttotal: 227ms\tremaining: 3.72s\n",
      "23:\tlearn: 0.4940390\ttotal: 237ms\tremaining: 3.71s\n",
      "24:\tlearn: 0.4928256\ttotal: 248ms\tremaining: 3.72s\n",
      "25:\tlearn: 0.4916885\ttotal: 260ms\tremaining: 3.75s\n",
      "26:\tlearn: 0.4905326\ttotal: 272ms\tremaining: 3.76s\n",
      "27:\tlearn: 0.4895024\ttotal: 283ms\tremaining: 3.76s\n",
      "28:\tlearn: 0.4883533\ttotal: 293ms\tremaining: 3.75s\n",
      "29:\tlearn: 0.4874028\ttotal: 302ms\tremaining: 3.73s\n",
      "30:\tlearn: 0.4865682\ttotal: 312ms\tremaining: 3.71s\n",
      "31:\tlearn: 0.4858673\ttotal: 322ms\tremaining: 3.71s\n",
      "32:\tlearn: 0.4853590\ttotal: 332ms\tremaining: 3.69s\n",
      "33:\tlearn: 0.4846984\ttotal: 342ms\tremaining: 3.68s\n",
      "34:\tlearn: 0.4841564\ttotal: 352ms\tremaining: 3.67s\n",
      "35:\tlearn: 0.4834812\ttotal: 362ms\tremaining: 3.66s\n",
      "36:\tlearn: 0.4828267\ttotal: 372ms\tremaining: 3.65s\n",
      "37:\tlearn: 0.4822428\ttotal: 381ms\tremaining: 3.63s\n",
      "38:\tlearn: 0.4818355\ttotal: 389ms\tremaining: 3.6s\n",
      "39:\tlearn: 0.4813856\ttotal: 398ms\tremaining: 3.58s\n",
      "40:\tlearn: 0.4809936\ttotal: 408ms\tremaining: 3.57s\n",
      "41:\tlearn: 0.4806127\ttotal: 418ms\tremaining: 3.56s\n",
      "42:\tlearn: 0.4803568\ttotal: 433ms\tremaining: 3.6s\n",
      "43:\tlearn: 0.4799924\ttotal: 443ms\tremaining: 3.59s\n",
      "44:\tlearn: 0.4797610\ttotal: 453ms\tremaining: 3.57s\n",
      "45:\tlearn: 0.4794303\ttotal: 462ms\tremaining: 3.55s\n",
      "46:\tlearn: 0.4792013\ttotal: 471ms\tremaining: 3.54s\n",
      "47:\tlearn: 0.4788593\ttotal: 481ms\tremaining: 3.53s\n",
      "48:\tlearn: 0.4785845\ttotal: 492ms\tremaining: 3.52s\n",
      "49:\tlearn: 0.4783361\ttotal: 502ms\tremaining: 3.51s\n",
      "50:\tlearn: 0.4781183\ttotal: 511ms\tremaining: 3.5s\n",
      "51:\tlearn: 0.4778526\ttotal: 521ms\tremaining: 3.49s\n",
      "52:\tlearn: 0.4776691\ttotal: 531ms\tremaining: 3.48s\n",
      "53:\tlearn: 0.4774285\ttotal: 553ms\tremaining: 3.54s\n",
      "54:\tlearn: 0.4772583\ttotal: 562ms\tremaining: 3.53s\n",
      "55:\tlearn: 0.4770986\ttotal: 571ms\tremaining: 3.51s\n",
      "56:\tlearn: 0.4768419\ttotal: 582ms\tremaining: 3.5s\n",
      "57:\tlearn: 0.4766658\ttotal: 591ms\tremaining: 3.48s\n",
      "58:\tlearn: 0.4764879\ttotal: 601ms\tremaining: 3.48s\n",
      "59:\tlearn: 0.4763441\ttotal: 612ms\tremaining: 3.47s\n",
      "60:\tlearn: 0.4761747\ttotal: 625ms\tremaining: 3.47s\n",
      "61:\tlearn: 0.4759950\ttotal: 636ms\tremaining: 3.47s\n",
      "62:\tlearn: 0.4758500\ttotal: 649ms\tremaining: 3.47s\n",
      "63:\tlearn: 0.4756519\ttotal: 659ms\tremaining: 3.46s\n",
      "64:\tlearn: 0.4755116\ttotal: 672ms\tremaining: 3.46s\n",
      "65:\tlearn: 0.4753042\ttotal: 684ms\tremaining: 3.46s\n",
      "66:\tlearn: 0.4751066\ttotal: 697ms\tremaining: 3.46s\n",
      "67:\tlearn: 0.4749937\ttotal: 707ms\tremaining: 3.45s\n",
      "68:\tlearn: 0.4748354\ttotal: 719ms\tremaining: 3.45s\n",
      "69:\tlearn: 0.4747315\ttotal: 730ms\tremaining: 3.44s\n",
      "70:\tlearn: 0.4745230\ttotal: 741ms\tremaining: 3.44s\n",
      "71:\tlearn: 0.4743492\ttotal: 753ms\tremaining: 3.43s\n",
      "72:\tlearn: 0.4742278\ttotal: 766ms\tremaining: 3.43s\n",
      "73:\tlearn: 0.4741334\ttotal: 779ms\tremaining: 3.43s\n",
      "74:\tlearn: 0.4740069\ttotal: 792ms\tremaining: 3.43s\n",
      "75:\tlearn: 0.4738508\ttotal: 803ms\tremaining: 3.42s\n",
      "76:\tlearn: 0.4736952\ttotal: 817ms\tremaining: 3.43s\n",
      "77:\tlearn: 0.4735924\ttotal: 831ms\tremaining: 3.43s\n",
      "78:\tlearn: 0.4735051\ttotal: 845ms\tremaining: 3.44s\n",
      "79:\tlearn: 0.4734264\ttotal: 858ms\tremaining: 3.43s\n",
      "80:\tlearn: 0.4733086\ttotal: 873ms\tremaining: 3.44s\n",
      "81:\tlearn: 0.4732192\ttotal: 887ms\tremaining: 3.44s\n",
      "82:\tlearn: 0.4730873\ttotal: 901ms\tremaining: 3.44s\n",
      "83:\tlearn: 0.4730094\ttotal: 914ms\tremaining: 3.44s\n",
      "84:\tlearn: 0.4729177\ttotal: 928ms\tremaining: 3.44s\n",
      "85:\tlearn: 0.4728012\ttotal: 942ms\tremaining: 3.44s\n",
      "86:\tlearn: 0.4727135\ttotal: 955ms\tremaining: 3.44s\n",
      "87:\tlearn: 0.4726112\ttotal: 969ms\tremaining: 3.44s\n",
      "88:\tlearn: 0.4725171\ttotal: 985ms\tremaining: 3.44s\n",
      "89:\tlearn: 0.4724455\ttotal: 1000ms\tremaining: 3.44s\n",
      "90:\tlearn: 0.4723649\ttotal: 1.01s\tremaining: 3.44s\n",
      "91:\tlearn: 0.4722464\ttotal: 1.03s\tremaining: 3.44s\n",
      "92:\tlearn: 0.4721833\ttotal: 1.04s\tremaining: 3.43s\n",
      "93:\tlearn: 0.4721183\ttotal: 1.05s\tremaining: 3.43s\n",
      "94:\tlearn: 0.4720116\ttotal: 1.07s\tremaining: 3.43s\n",
      "95:\tlearn: 0.4719356\ttotal: 1.08s\tremaining: 3.42s\n",
      "96:\tlearn: 0.4718253\ttotal: 1.09s\tremaining: 3.42s\n",
      "97:\tlearn: 0.4717559\ttotal: 1.11s\tremaining: 3.41s\n",
      "98:\tlearn: 0.4716469\ttotal: 1.12s\tremaining: 3.4s\n",
      "99:\tlearn: 0.4715816\ttotal: 1.13s\tremaining: 3.4s\n",
      "100:\tlearn: 0.4715002\ttotal: 1.15s\tremaining: 3.4s\n",
      "101:\tlearn: 0.4714026\ttotal: 1.16s\tremaining: 3.4s\n",
      "102:\tlearn: 0.4713297\ttotal: 1.18s\tremaining: 3.39s\n",
      "103:\tlearn: 0.4712492\ttotal: 1.19s\tremaining: 3.39s\n",
      "104:\tlearn: 0.4712026\ttotal: 1.21s\tremaining: 3.39s\n",
      "105:\tlearn: 0.4711277\ttotal: 1.22s\tremaining: 3.39s\n",
      "106:\tlearn: 0.4710651\ttotal: 1.26s\tremaining: 3.46s\n",
      "107:\tlearn: 0.4709894\ttotal: 1.32s\tremaining: 3.56s\n",
      "108:\tlearn: 0.4709245\ttotal: 1.35s\tremaining: 3.6s\n",
      "109:\tlearn: 0.4708629\ttotal: 1.37s\tremaining: 3.61s\n",
      "110:\tlearn: 0.4707779\ttotal: 1.39s\tremaining: 3.62s\n",
      "111:\tlearn: 0.4707049\ttotal: 1.41s\tremaining: 3.62s\n",
      "112:\tlearn: 0.4706318\ttotal: 1.42s\tremaining: 3.61s\n",
      "113:\tlearn: 0.4705298\ttotal: 1.43s\tremaining: 3.6s\n",
      "114:\tlearn: 0.4704841\ttotal: 1.45s\tremaining: 3.59s\n",
      "115:\tlearn: 0.4704325\ttotal: 1.47s\tremaining: 3.59s\n",
      "116:\tlearn: 0.4703156\ttotal: 1.49s\tremaining: 3.6s\n",
      "117:\tlearn: 0.4702755\ttotal: 1.5s\tremaining: 3.59s\n",
      "118:\tlearn: 0.4702289\ttotal: 1.52s\tremaining: 3.59s\n",
      "119:\tlearn: 0.4701893\ttotal: 1.53s\tremaining: 3.58s\n",
      "120:\tlearn: 0.4701511\ttotal: 1.55s\tremaining: 3.57s\n",
      "121:\tlearn: 0.4700606\ttotal: 1.56s\tremaining: 3.57s\n",
      "122:\tlearn: 0.4700342\ttotal: 1.58s\tremaining: 3.56s\n",
      "123:\tlearn: 0.4699793\ttotal: 1.59s\tremaining: 3.55s\n",
      "124:\tlearn: 0.4699304\ttotal: 1.61s\tremaining: 3.54s\n",
      "125:\tlearn: 0.4698699\ttotal: 1.62s\tremaining: 3.52s\n",
      "126:\tlearn: 0.4697960\ttotal: 1.63s\tremaining: 3.51s\n",
      "127:\tlearn: 0.4697222\ttotal: 1.65s\tremaining: 3.5s\n",
      "128:\tlearn: 0.4696728\ttotal: 1.66s\tremaining: 3.49s\n",
      "129:\tlearn: 0.4696218\ttotal: 1.68s\tremaining: 3.48s\n",
      "130:\tlearn: 0.4695847\ttotal: 1.69s\tremaining: 3.47s\n",
      "131:\tlearn: 0.4695256\ttotal: 1.71s\tremaining: 3.46s\n",
      "132:\tlearn: 0.4694854\ttotal: 1.72s\tremaining: 3.45s\n",
      "133:\tlearn: 0.4694376\ttotal: 1.73s\tremaining: 3.44s\n",
      "134:\tlearn: 0.4693940\ttotal: 1.75s\tremaining: 3.43s\n",
      "135:\tlearn: 0.4693379\ttotal: 1.76s\tremaining: 3.42s\n",
      "136:\tlearn: 0.4692993\ttotal: 1.77s\tremaining: 3.41s\n",
      "137:\tlearn: 0.4692424\ttotal: 1.79s\tremaining: 3.4s\n",
      "138:\tlearn: 0.4691804\ttotal: 1.8s\tremaining: 3.38s\n",
      "139:\tlearn: 0.4691537\ttotal: 1.81s\tremaining: 3.37s\n",
      "140:\tlearn: 0.4691162\ttotal: 1.83s\tremaining: 3.35s\n",
      "141:\tlearn: 0.4690837\ttotal: 1.84s\tremaining: 3.34s\n",
      "142:\tlearn: 0.4690466\ttotal: 1.85s\tremaining: 3.33s\n",
      "143:\tlearn: 0.4689959\ttotal: 1.87s\tremaining: 3.32s\n",
      "144:\tlearn: 0.4689666\ttotal: 1.88s\tremaining: 3.31s\n",
      "145:\tlearn: 0.4689183\ttotal: 1.9s\tremaining: 3.3s\n",
      "146:\tlearn: 0.4688762\ttotal: 1.91s\tremaining: 3.29s\n",
      "147:\tlearn: 0.4688342\ttotal: 1.92s\tremaining: 3.27s\n",
      "148:\tlearn: 0.4687776\ttotal: 1.94s\tremaining: 3.26s\n",
      "149:\tlearn: 0.4687384\ttotal: 1.95s\tremaining: 3.25s\n",
      "150:\tlearn: 0.4686879\ttotal: 1.97s\tremaining: 3.24s\n",
      "151:\tlearn: 0.4686440\ttotal: 1.98s\tremaining: 3.23s\n",
      "152:\tlearn: 0.4685929\ttotal: 2s\tremaining: 3.22s\n",
      "153:\tlearn: 0.4685492\ttotal: 2.01s\tremaining: 3.21s\n",
      "154:\tlearn: 0.4684905\ttotal: 2.02s\tremaining: 3.2s\n",
      "155:\tlearn: 0.4684597\ttotal: 2.04s\tremaining: 3.19s\n",
      "156:\tlearn: 0.4683869\ttotal: 2.05s\tremaining: 3.18s\n",
      "157:\tlearn: 0.4683527\ttotal: 2.07s\tremaining: 3.17s\n",
      "158:\tlearn: 0.4683241\ttotal: 2.08s\tremaining: 3.15s\n",
      "159:\tlearn: 0.4682882\ttotal: 2.09s\tremaining: 3.14s\n",
      "160:\tlearn: 0.4682612\ttotal: 2.11s\tremaining: 3.13s\n",
      "161:\tlearn: 0.4682186\ttotal: 2.12s\tremaining: 3.12s\n",
      "162:\tlearn: 0.4681802\ttotal: 2.13s\tremaining: 3.1s\n",
      "163:\tlearn: 0.4681503\ttotal: 2.15s\tremaining: 3.09s\n",
      "164:\tlearn: 0.4681221\ttotal: 2.16s\tremaining: 3.08s\n",
      "165:\tlearn: 0.4681014\ttotal: 2.18s\tremaining: 3.07s\n",
      "166:\tlearn: 0.4680590\ttotal: 2.19s\tremaining: 3.06s\n",
      "167:\tlearn: 0.4680287\ttotal: 2.21s\tremaining: 3.05s\n",
      "168:\tlearn: 0.4679597\ttotal: 2.22s\tremaining: 3.04s\n",
      "169:\tlearn: 0.4679138\ttotal: 2.24s\tremaining: 3.03s\n",
      "170:\tlearn: 0.4678723\ttotal: 2.25s\tremaining: 3.01s\n",
      "171:\tlearn: 0.4678435\ttotal: 2.26s\tremaining: 3s\n",
      "172:\tlearn: 0.4677786\ttotal: 2.28s\tremaining: 2.99s\n",
      "173:\tlearn: 0.4677549\ttotal: 2.29s\tremaining: 2.97s\n",
      "174:\tlearn: 0.4676987\ttotal: 2.3s\tremaining: 2.96s\n",
      "175:\tlearn: 0.4676463\ttotal: 2.31s\tremaining: 2.95s\n",
      "176:\tlearn: 0.4676039\ttotal: 2.33s\tremaining: 2.93s\n",
      "177:\tlearn: 0.4675751\ttotal: 2.34s\tremaining: 2.92s\n",
      "178:\tlearn: 0.4675409\ttotal: 2.35s\tremaining: 2.9s\n",
      "179:\tlearn: 0.4674948\ttotal: 2.37s\tremaining: 2.89s\n",
      "180:\tlearn: 0.4674547\ttotal: 2.38s\tremaining: 2.88s\n",
      "181:\tlearn: 0.4674302\ttotal: 2.39s\tremaining: 2.87s\n",
      "182:\tlearn: 0.4673866\ttotal: 2.41s\tremaining: 2.86s\n",
      "183:\tlearn: 0.4673500\ttotal: 2.42s\tremaining: 2.85s\n",
      "184:\tlearn: 0.4673174\ttotal: 2.45s\tremaining: 2.84s\n",
      "185:\tlearn: 0.4672977\ttotal: 2.46s\tremaining: 2.83s\n",
      "186:\tlearn: 0.4672685\ttotal: 2.48s\tremaining: 2.83s\n",
      "187:\tlearn: 0.4672378\ttotal: 2.51s\tremaining: 2.83s\n",
      "188:\tlearn: 0.4672165\ttotal: 2.56s\tremaining: 2.86s\n",
      "189:\tlearn: 0.4672010\ttotal: 2.58s\tremaining: 2.85s\n",
      "190:\tlearn: 0.4671575\ttotal: 2.59s\tremaining: 2.84s\n",
      "191:\tlearn: 0.4671120\ttotal: 2.61s\tremaining: 2.83s\n",
      "192:\tlearn: 0.4670702\ttotal: 2.63s\tremaining: 2.82s\n",
      "193:\tlearn: 0.4670168\ttotal: 2.65s\tremaining: 2.82s\n",
      "194:\tlearn: 0.4669953\ttotal: 2.67s\tremaining: 2.81s\n",
      "195:\tlearn: 0.4669546\ttotal: 2.69s\tremaining: 2.8s\n",
      "196:\tlearn: 0.4669056\ttotal: 2.71s\tremaining: 2.79s\n",
      "197:\tlearn: 0.4668584\ttotal: 2.72s\tremaining: 2.78s\n",
      "198:\tlearn: 0.4668291\ttotal: 2.74s\tremaining: 2.77s\n",
      "199:\tlearn: 0.4667979\ttotal: 2.76s\tremaining: 2.76s\n",
      "200:\tlearn: 0.4667715\ttotal: 2.77s\tremaining: 2.75s\n",
      "201:\tlearn: 0.4667186\ttotal: 2.79s\tremaining: 2.73s\n",
      "202:\tlearn: 0.4666559\ttotal: 2.8s\tremaining: 2.72s\n",
      "203:\tlearn: 0.4666003\ttotal: 2.81s\tremaining: 2.7s\n",
      "204:\tlearn: 0.4665736\ttotal: 2.82s\tremaining: 2.69s\n",
      "205:\tlearn: 0.4665490\ttotal: 2.84s\tremaining: 2.67s\n",
      "206:\tlearn: 0.4665150\ttotal: 2.85s\tremaining: 2.66s\n",
      "207:\tlearn: 0.4664701\ttotal: 2.86s\tremaining: 2.64s\n",
      "208:\tlearn: 0.4664323\ttotal: 2.88s\tremaining: 2.63s\n",
      "209:\tlearn: 0.4664021\ttotal: 2.89s\tremaining: 2.61s\n",
      "210:\tlearn: 0.4663256\ttotal: 2.9s\tremaining: 2.6s\n",
      "211:\tlearn: 0.4662764\ttotal: 2.91s\tremaining: 2.58s\n",
      "212:\tlearn: 0.4662458\ttotal: 2.93s\tremaining: 2.57s\n",
      "213:\tlearn: 0.4662050\ttotal: 2.94s\tremaining: 2.56s\n",
      "214:\tlearn: 0.4661653\ttotal: 2.95s\tremaining: 2.54s\n",
      "215:\tlearn: 0.4661351\ttotal: 2.97s\tremaining: 2.53s\n",
      "216:\tlearn: 0.4661055\ttotal: 2.98s\tremaining: 2.51s\n",
      "217:\tlearn: 0.4660875\ttotal: 2.99s\tremaining: 2.5s\n",
      "218:\tlearn: 0.4660633\ttotal: 3.01s\tremaining: 2.49s\n",
      "219:\tlearn: 0.4660299\ttotal: 3.02s\tremaining: 2.47s\n",
      "220:\tlearn: 0.4659738\ttotal: 3.04s\tremaining: 2.46s\n",
      "221:\tlearn: 0.4659522\ttotal: 3.05s\tremaining: 2.44s\n",
      "222:\tlearn: 0.4659352\ttotal: 3.06s\tremaining: 2.43s\n",
      "223:\tlearn: 0.4659049\ttotal: 3.07s\tremaining: 2.42s\n",
      "224:\tlearn: 0.4658731\ttotal: 3.09s\tremaining: 2.4s\n",
      "225:\tlearn: 0.4658319\ttotal: 3.1s\tremaining: 2.39s\n",
      "226:\tlearn: 0.4657932\ttotal: 3.11s\tremaining: 2.37s\n",
      "227:\tlearn: 0.4657750\ttotal: 3.13s\tremaining: 2.36s\n",
      "228:\tlearn: 0.4657331\ttotal: 3.14s\tremaining: 2.34s\n",
      "229:\tlearn: 0.4657059\ttotal: 3.15s\tremaining: 2.33s\n",
      "230:\tlearn: 0.4656853\ttotal: 3.17s\tremaining: 2.32s\n",
      "231:\tlearn: 0.4656530\ttotal: 3.18s\tremaining: 2.3s\n",
      "232:\tlearn: 0.4656156\ttotal: 3.19s\tremaining: 2.29s\n",
      "233:\tlearn: 0.4655708\ttotal: 3.21s\tremaining: 2.27s\n",
      "234:\tlearn: 0.4655143\ttotal: 3.22s\tremaining: 2.26s\n",
      "235:\tlearn: 0.4654768\ttotal: 3.23s\tremaining: 2.25s\n",
      "236:\tlearn: 0.4654450\ttotal: 3.25s\tremaining: 2.23s\n",
      "237:\tlearn: 0.4654312\ttotal: 3.26s\tremaining: 2.22s\n",
      "238:\tlearn: 0.4654264\ttotal: 3.27s\tremaining: 2.2s\n",
      "239:\tlearn: 0.4653977\ttotal: 3.28s\tremaining: 2.19s\n",
      "240:\tlearn: 0.4653706\ttotal: 3.3s\tremaining: 2.18s\n",
      "241:\tlearn: 0.4653313\ttotal: 3.31s\tremaining: 2.16s\n",
      "242:\tlearn: 0.4652927\ttotal: 3.33s\tremaining: 2.15s\n",
      "243:\tlearn: 0.4652457\ttotal: 3.34s\tremaining: 2.13s\n",
      "244:\tlearn: 0.4651989\ttotal: 3.35s\tremaining: 2.12s\n",
      "245:\tlearn: 0.4651711\ttotal: 3.37s\tremaining: 2.11s\n",
      "246:\tlearn: 0.4651480\ttotal: 3.38s\tremaining: 2.09s\n",
      "247:\tlearn: 0.4651008\ttotal: 3.39s\tremaining: 2.08s\n",
      "248:\tlearn: 0.4650687\ttotal: 3.4s\tremaining: 2.06s\n",
      "249:\tlearn: 0.4650157\ttotal: 3.42s\tremaining: 2.05s\n",
      "250:\tlearn: 0.4649643\ttotal: 3.43s\tremaining: 2.04s\n",
      "251:\tlearn: 0.4649373\ttotal: 3.44s\tremaining: 2.02s\n",
      "252:\tlearn: 0.4649120\ttotal: 3.46s\tremaining: 2.01s\n",
      "253:\tlearn: 0.4648697\ttotal: 3.47s\tremaining: 1.99s\n",
      "254:\tlearn: 0.4648310\ttotal: 3.48s\tremaining: 1.98s\n",
      "255:\tlearn: 0.4648036\ttotal: 3.5s\tremaining: 1.97s\n",
      "256:\tlearn: 0.4647783\ttotal: 3.51s\tremaining: 1.96s\n",
      "257:\tlearn: 0.4647658\ttotal: 3.53s\tremaining: 1.94s\n",
      "258:\tlearn: 0.4647323\ttotal: 3.54s\tremaining: 1.93s\n",
      "259:\tlearn: 0.4646982\ttotal: 3.56s\tremaining: 1.92s\n",
      "260:\tlearn: 0.4646630\ttotal: 3.58s\tremaining: 1.91s\n",
      "261:\tlearn: 0.4646284\ttotal: 3.59s\tremaining: 1.89s\n",
      "262:\tlearn: 0.4645979\ttotal: 3.61s\tremaining: 1.88s\n",
      "263:\tlearn: 0.4645400\ttotal: 3.62s\tremaining: 1.87s\n",
      "264:\tlearn: 0.4645159\ttotal: 3.64s\tremaining: 1.85s\n",
      "265:\tlearn: 0.4644693\ttotal: 3.65s\tremaining: 1.84s\n",
      "266:\tlearn: 0.4644569\ttotal: 3.66s\tremaining: 1.82s\n",
      "267:\tlearn: 0.4644268\ttotal: 3.67s\tremaining: 1.81s\n",
      "268:\tlearn: 0.4643829\ttotal: 3.69s\tremaining: 1.8s\n",
      "269:\tlearn: 0.4643793\ttotal: 3.7s\tremaining: 1.78s\n",
      "270:\tlearn: 0.4643512\ttotal: 3.72s\tremaining: 1.77s\n",
      "271:\tlearn: 0.4643467\ttotal: 3.73s\tremaining: 1.75s\n",
      "272:\tlearn: 0.4643436\ttotal: 3.74s\tremaining: 1.74s\n",
      "273:\tlearn: 0.4642975\ttotal: 3.76s\tremaining: 1.73s\n",
      "274:\tlearn: 0.4642602\ttotal: 3.77s\tremaining: 1.72s\n",
      "275:\tlearn: 0.4642370\ttotal: 3.79s\tremaining: 1.7s\n",
      "276:\tlearn: 0.4642069\ttotal: 3.81s\tremaining: 1.69s\n",
      "277:\tlearn: 0.4641805\ttotal: 3.82s\tremaining: 1.68s\n",
      "278:\tlearn: 0.4641503\ttotal: 3.83s\tremaining: 1.66s\n",
      "279:\tlearn: 0.4641303\ttotal: 3.85s\tremaining: 1.65s\n",
      "280:\tlearn: 0.4641087\ttotal: 3.86s\tremaining: 1.64s\n",
      "281:\tlearn: 0.4640845\ttotal: 3.88s\tremaining: 1.62s\n",
      "282:\tlearn: 0.4640527\ttotal: 3.89s\tremaining: 1.61s\n",
      "283:\tlearn: 0.4640231\ttotal: 3.9s\tremaining: 1.59s\n",
      "284:\tlearn: 0.4639974\ttotal: 3.92s\tremaining: 1.58s\n",
      "285:\tlearn: 0.4639604\ttotal: 3.93s\tremaining: 1.57s\n",
      "286:\tlearn: 0.4639282\ttotal: 3.95s\tremaining: 1.55s\n",
      "287:\tlearn: 0.4638911\ttotal: 3.96s\tremaining: 1.54s\n",
      "288:\tlearn: 0.4638677\ttotal: 3.98s\tremaining: 1.53s\n",
      "289:\tlearn: 0.4638344\ttotal: 3.99s\tremaining: 1.51s\n",
      "290:\tlearn: 0.4638179\ttotal: 4s\tremaining: 1.5s\n",
      "291:\tlearn: 0.4637962\ttotal: 4.02s\tremaining: 1.49s\n",
      "292:\tlearn: 0.4637634\ttotal: 4.03s\tremaining: 1.47s\n",
      "293:\tlearn: 0.4637218\ttotal: 4.04s\tremaining: 1.46s\n",
      "294:\tlearn: 0.4636863\ttotal: 4.05s\tremaining: 1.44s\n",
      "295:\tlearn: 0.4636517\ttotal: 4.07s\tremaining: 1.43s\n",
      "296:\tlearn: 0.4636253\ttotal: 4.08s\tremaining: 1.41s\n",
      "297:\tlearn: 0.4635968\ttotal: 4.09s\tremaining: 1.4s\n",
      "298:\tlearn: 0.4635701\ttotal: 4.1s\tremaining: 1.39s\n",
      "299:\tlearn: 0.4635427\ttotal: 4.12s\tremaining: 1.37s\n",
      "300:\tlearn: 0.4635357\ttotal: 4.13s\tremaining: 1.36s\n",
      "301:\tlearn: 0.4635124\ttotal: 4.14s\tremaining: 1.34s\n",
      "302:\tlearn: 0.4634816\ttotal: 4.15s\tremaining: 1.33s\n",
      "303:\tlearn: 0.4634754\ttotal: 4.17s\tremaining: 1.31s\n",
      "304:\tlearn: 0.4634454\ttotal: 4.18s\tremaining: 1.3s\n",
      "305:\tlearn: 0.4634416\ttotal: 4.19s\tremaining: 1.29s\n",
      "306:\tlearn: 0.4634178\ttotal: 4.2s\tremaining: 1.27s\n",
      "307:\tlearn: 0.4634004\ttotal: 4.21s\tremaining: 1.26s\n",
      "308:\tlearn: 0.4633762\ttotal: 4.23s\tremaining: 1.24s\n",
      "309:\tlearn: 0.4633532\ttotal: 4.24s\tremaining: 1.23s\n",
      "310:\tlearn: 0.4633190\ttotal: 4.25s\tremaining: 1.22s\n",
      "311:\tlearn: 0.4632955\ttotal: 4.26s\tremaining: 1.2s\n",
      "312:\tlearn: 0.4632686\ttotal: 4.27s\tremaining: 1.19s\n",
      "313:\tlearn: 0.4632435\ttotal: 4.29s\tremaining: 1.17s\n",
      "314:\tlearn: 0.4632154\ttotal: 4.3s\tremaining: 1.16s\n",
      "315:\tlearn: 0.4631775\ttotal: 4.31s\tremaining: 1.15s\n",
      "316:\tlearn: 0.4631549\ttotal: 4.32s\tremaining: 1.13s\n",
      "317:\tlearn: 0.4631284\ttotal: 4.33s\tremaining: 1.12s\n",
      "318:\tlearn: 0.4630970\ttotal: 4.34s\tremaining: 1.1s\n",
      "319:\tlearn: 0.4630730\ttotal: 4.35s\tremaining: 1.09s\n",
      "320:\tlearn: 0.4630428\ttotal: 4.37s\tremaining: 1.07s\n",
      "321:\tlearn: 0.4630184\ttotal: 4.38s\tremaining: 1.06s\n",
      "322:\tlearn: 0.4629977\ttotal: 4.39s\tremaining: 1.05s\n",
      "323:\tlearn: 0.4629728\ttotal: 4.4s\tremaining: 1.03s\n",
      "324:\tlearn: 0.4629500\ttotal: 4.41s\tremaining: 1.02s\n",
      "325:\tlearn: 0.4629299\ttotal: 4.43s\tremaining: 1s\n",
      "326:\tlearn: 0.4629015\ttotal: 4.44s\tremaining: 991ms\n",
      "327:\tlearn: 0.4628757\ttotal: 4.45s\tremaining: 977ms\n",
      "328:\tlearn: 0.4628507\ttotal: 4.46s\tremaining: 963ms\n",
      "329:\tlearn: 0.4628121\ttotal: 4.47s\tremaining: 949ms\n",
      "330:\tlearn: 0.4627838\ttotal: 4.49s\tremaining: 935ms\n",
      "331:\tlearn: 0.4627532\ttotal: 4.5s\tremaining: 921ms\n",
      "332:\tlearn: 0.4627295\ttotal: 4.51s\tremaining: 907ms\n",
      "333:\tlearn: 0.4627108\ttotal: 4.52s\tremaining: 894ms\n",
      "334:\tlearn: 0.4626904\ttotal: 4.53s\tremaining: 880ms\n",
      "335:\tlearn: 0.4626718\ttotal: 4.54s\tremaining: 866ms\n",
      "336:\tlearn: 0.4626169\ttotal: 4.56s\tremaining: 852ms\n",
      "337:\tlearn: 0.4625952\ttotal: 4.57s\tremaining: 838ms\n",
      "338:\tlearn: 0.4625660\ttotal: 4.58s\tremaining: 824ms\n",
      "339:\tlearn: 0.4625466\ttotal: 4.59s\tremaining: 810ms\n",
      "340:\tlearn: 0.4625144\ttotal: 4.6s\tremaining: 796ms\n",
      "341:\tlearn: 0.4624952\ttotal: 4.61s\tremaining: 783ms\n",
      "342:\tlearn: 0.4624545\ttotal: 4.63s\tremaining: 769ms\n",
      "343:\tlearn: 0.4624485\ttotal: 4.64s\tremaining: 755ms\n",
      "344:\tlearn: 0.4624210\ttotal: 4.65s\tremaining: 741ms\n",
      "345:\tlearn: 0.4624015\ttotal: 4.66s\tremaining: 728ms\n",
      "346:\tlearn: 0.4623665\ttotal: 4.68s\tremaining: 714ms\n",
      "347:\tlearn: 0.4623367\ttotal: 4.7s\tremaining: 703ms\n",
      "348:\tlearn: 0.4623145\ttotal: 4.72s\tremaining: 689ms\n",
      "349:\tlearn: 0.4622891\ttotal: 4.73s\tremaining: 676ms\n",
      "350:\tlearn: 0.4622658\ttotal: 4.74s\tremaining: 662ms\n",
      "351:\tlearn: 0.4622306\ttotal: 4.76s\tremaining: 649ms\n",
      "352:\tlearn: 0.4622063\ttotal: 4.77s\tremaining: 635ms\n",
      "353:\tlearn: 0.4621817\ttotal: 4.78s\tremaining: 622ms\n",
      "354:\tlearn: 0.4621678\ttotal: 4.8s\tremaining: 608ms\n",
      "355:\tlearn: 0.4621463\ttotal: 4.81s\tremaining: 594ms\n",
      "356:\tlearn: 0.4621184\ttotal: 4.82s\tremaining: 581ms\n",
      "357:\tlearn: 0.4621011\ttotal: 4.83s\tremaining: 567ms\n",
      "358:\tlearn: 0.4620799\ttotal: 4.85s\tremaining: 554ms\n",
      "359:\tlearn: 0.4620596\ttotal: 4.86s\tremaining: 540ms\n",
      "360:\tlearn: 0.4620419\ttotal: 4.87s\tremaining: 526ms\n",
      "361:\tlearn: 0.4620049\ttotal: 4.89s\tremaining: 513ms\n",
      "362:\tlearn: 0.4619779\ttotal: 4.9s\tremaining: 499ms\n",
      "363:\tlearn: 0.4619516\ttotal: 4.91s\tremaining: 486ms\n",
      "364:\tlearn: 0.4619205\ttotal: 4.92s\tremaining: 472ms\n",
      "365:\tlearn: 0.4619027\ttotal: 4.94s\tremaining: 459ms\n",
      "366:\tlearn: 0.4618931\ttotal: 4.95s\tremaining: 445ms\n",
      "367:\tlearn: 0.4618673\ttotal: 4.96s\tremaining: 431ms\n",
      "368:\tlearn: 0.4618364\ttotal: 4.97s\tremaining: 418ms\n",
      "369:\tlearn: 0.4618102\ttotal: 4.99s\tremaining: 404ms\n",
      "370:\tlearn: 0.4617788\ttotal: 5s\tremaining: 391ms\n",
      "371:\tlearn: 0.4617438\ttotal: 5.01s\tremaining: 377ms\n",
      "372:\tlearn: 0.4617218\ttotal: 5.03s\tremaining: 364ms\n",
      "373:\tlearn: 0.4616930\ttotal: 5.04s\tremaining: 350ms\n",
      "374:\tlearn: 0.4616761\ttotal: 5.05s\tremaining: 337ms\n",
      "375:\tlearn: 0.4616552\ttotal: 5.07s\tremaining: 323ms\n",
      "376:\tlearn: 0.4616334\ttotal: 5.08s\tremaining: 310ms\n",
      "377:\tlearn: 0.4616257\ttotal: 5.09s\tremaining: 296ms\n",
      "378:\tlearn: 0.4616087\ttotal: 5.11s\tremaining: 283ms\n",
      "379:\tlearn: 0.4615847\ttotal: 5.12s\tremaining: 269ms\n",
      "380:\tlearn: 0.4615585\ttotal: 5.13s\tremaining: 256ms\n",
      "381:\tlearn: 0.4615330\ttotal: 5.14s\tremaining: 242ms\n",
      "382:\tlearn: 0.4615114\ttotal: 5.16s\tremaining: 229ms\n",
      "383:\tlearn: 0.4615048\ttotal: 5.17s\tremaining: 215ms\n",
      "384:\tlearn: 0.4614842\ttotal: 5.18s\tremaining: 202ms\n",
      "385:\tlearn: 0.4614615\ttotal: 5.24s\tremaining: 190ms\n",
      "386:\tlearn: 0.4614462\ttotal: 5.26s\tremaining: 177ms\n",
      "387:\tlearn: 0.4614220\ttotal: 5.27s\tremaining: 163ms\n",
      "388:\tlearn: 0.4613959\ttotal: 5.28s\tremaining: 149ms\n",
      "389:\tlearn: 0.4613725\ttotal: 5.29s\tremaining: 136ms\n",
      "390:\tlearn: 0.4613464\ttotal: 5.31s\tremaining: 122ms\n",
      "391:\tlearn: 0.4613270\ttotal: 5.32s\tremaining: 109ms\n",
      "392:\tlearn: 0.4613089\ttotal: 5.33s\tremaining: 95ms\n",
      "393:\tlearn: 0.4612833\ttotal: 5.35s\tremaining: 81.4ms\n",
      "394:\tlearn: 0.4612398\ttotal: 5.36s\tremaining: 67.8ms\n",
      "395:\tlearn: 0.4612243\ttotal: 5.37s\tremaining: 54.3ms\n",
      "396:\tlearn: 0.4612014\ttotal: 5.38s\tremaining: 40.7ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 14:49:41,750 - INFO - Saving the model, imputer, and scaler...\n",
      "2024-07-29 14:49:41,755 - INFO - Model, imputer, and scaler saved successfully.\n",
      "2024-07-29 14:49:41,755 - INFO - Model training completed and saved.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397:\tlearn: 0.4611770\ttotal: 5.4s\tremaining: 27.1ms\n",
      "398:\tlearn: 0.4611493\ttotal: 5.41s\tremaining: 13.6ms\n",
      "399:\tlearn: 0.4611193\ttotal: 5.42s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def load_data(file_path):\n",
    "    \"\"\"Load the dataset from the specified file path.\"\"\"\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "def filter_data(data):\n",
    "    \"\"\"Apply any necessary data filtering here.\"\"\"\n",
    "    # Implement your data filtering logic\n",
    "    return data\n",
    "\n",
    "def drop_columns(data, columns):\n",
    "    \"\"\"Drop the specified columns from the dataset.\"\"\"\n",
    "    return data.drop(columns=columns, errors='ignore')\n",
    "\n",
    "def preprocess_data(data, categorical_cols, numerical_cols, target_col):\n",
    "    \"\"\"Encode categorical variables, handle missing values, and scale numerical features.\"\"\"\n",
    "    # Encode categorical variables\n",
    "    data_encoded = pd.get_dummies(data, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "    # Check if target column is present\n",
    "    if target_col not in data_encoded.columns:\n",
    "        logging.error(f\"Target column '{target_col}' not found in data columns: {data_encoded.columns}\")\n",
    "        raise KeyError(f\"Target column '{target_col}' not found in data columns\")\n",
    "\n",
    "    X = data_encoded.drop(columns=[target_col])\n",
    "    y = data_encoded[target_col]\n",
    "\n",
    "    # Check for non-numeric data in X\n",
    "    non_numeric_columns = X.select_dtypes(include=['object']).columns.tolist()\n",
    "    if non_numeric_columns:\n",
    "        logging.error(f\"Non-numeric data found in columns: {non_numeric_columns}\")\n",
    "        raise ValueError(f\"Non-numeric data found in columns: {non_numeric_columns}\")\n",
    "\n",
    "    # Check for unique values in each column\n",
    "    for col in non_numeric_columns:\n",
    "        unique_values = X[col].unique()\n",
    "        logging.info(f\"Column {col} has unique values: {unique_values}\")\n",
    "\n",
    "    # Handle missing values\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "    # Scale numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "    return X_scaled, y, imputer, scaler\n",
    "\n",
    "\n",
    "def train_model(X, y):\n",
    "    \"\"\"Train the CatBoostClassifier with the specified parameters.\"\"\"\n",
    "    model = CatBoostClassifier(depth=5, iterations=400, l2_leaf_reg=3, learning_rate=0.06, random_seed=42, logging_level='Verbose')\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def save_model(model, imputer, scaler, model_path, imputer_path, scaler_path):\n",
    "    \"\"\"Save the trained model, imputer, and scaler to disk.\"\"\"\n",
    "    model.save_model(model_path)\n",
    "    joblib.dump(imputer, imputer_path)\n",
    "    joblib.dump(scaler, scaler_path)\n",
    "    logging.info(\"Model, imputer, and scaler saved successfully.\")\n",
    "\n",
    "def main():\n",
    "    # File paths\n",
    "    train_file_path = '/Users/fabrizioferrari/Desktop/final boss/Training_Set_Columnas_Condensed.csv'\n",
    "    model_path = '/Users/fabrizioferrari/Desktop/final boss/catboost_model.cbm'\n",
    "    imputer_path = '/Users/fabrizioferrari/Desktop/final boss/imputer.pkl'\n",
    "    scaler_path = '/Users/fabrizioferrari/Desktop/final boss/scaler.pkl'\n",
    "    \n",
    "    # Columns to drop\n",
    "    columns_to_drop = [\n",
    "    \"Año de Fecha Cierre\", \"Fecha Cierre\", \"Fecha Colocacion\", \"Analista\", \n",
    "    \"APORTA_IVA\", \"Aportaips\", \"Aproblinea\", \"Aprobscoring\", \"Atraso\", \n",
    "    \"CALIFICACION\",\"CIUDADLAB\",'CIRCUITO_OPE', \"CLIENTEFORMAL\", \"COBROWALTON\", \"COD_EMPRESA1_LAB\", \n",
    "    \"COD_EMPRESA2_LAB\", \"Condicionado\", \"Controlscoring\", \"CUENTA\", \n",
    "    \"CUOTAS_PEND\", \"CUOTASPAGADAS\", \"EMPRESA_PUBLICA1_LAB\", \n",
    "    \"EMPRESA_PUBLICA2_LAB\", \"EMPRESA1_LAB\", \"EMPRESA2_LAB\", \n",
    "    \"ESTADO_OPERACION\", \"Excepcion\", \"EXCEPCIONANALISTA\", \n",
    "    \"EXCEPCIONESTADO\", \"EXCEPCIONINSTANCIA\", \"EXCEPCIONMOTIVO\", \n",
    "    \"EXCEPCIONTIPO\", \"Faja\", \"Fecha Venta\", \"FECHA_CANCELACION\", \n",
    "    \"Franquicia\", \"HABILITA_PROD1_BNF\", \"HABILITA_PROD2_BNF\", \n",
    "    \"INTERES_VTA\", \"INTERES2\", \"IVA_LEY\", \"MONTO_ANTERIOR\", \n",
    "    \"MONTODESEMBOLSADO\", \"OPE_NUEVA\", \"OPEPARALELA\", \"Operacion\", \n",
    "    \"OPERACIONIPS\", \"PATENTE_COMERCIAL\", \"Rechazocarga\", \"RUC_EMPRESA1_LAB\", \n",
    "    \"RUC_EMPRESA2_LAB\", \"Saldo Capital\", \"Score\", \"SCORE_BICSA\", \n",
    "    \"SCORE_DATALAB\", \"SECTOR_ECONOMICO\", \"SITUACION\", \"Sucursal\", \n",
    "    \"Sucursaltipo\", \"Supervisor\",\"Tipo_Aprobacion\", \"ULTIMO_ATRASO\", \n",
    "    \"Vendedor\",\"Pagare\",\"Mora Final %\",\"Mora Final\",\"Atraso30\",\"Atraso60\",\"Atraso120\",\"Atraso150\",\"Atraso90\",\"Capital anterior\",\"Capital Venta\"\n",
    "]\n",
    "\n",
    "    # Categorical and numerical columns\n",
    "    categorical_cols = [ \"Banca\", \"CALIFICACION_ANTERIOR\",  \n",
    "                        \"MARCA\",  \"SEXO\", \"Tipo\", \"Departamento\",  \"Medio\",  \"Canal\"]\n",
    "    numerical_cols = [\"Cant. Cuotas\", \"Capital actual\", \"Edad\", \"INGRESO_CLIENTE\", \"Valor Cuota\"]\n",
    "    \n",
    "    target_col = 'Atraso180'\n",
    "\n",
    "    # Load and preprocess data\n",
    "    logging.info(\"Loading data...\")\n",
    "    train_data = load_data(train_file_path)\n",
    "    logging.info(f\"Columns in the dataset after loading: {train_data.columns.tolist()}\")\n",
    "    \n",
    "    logging.info(\"Filtering data...\")\n",
    "    train_data = filter_data(train_data)\n",
    "    \n",
    "    logging.info(\"Dropping unnecessary columns...\")\n",
    "    train_data = drop_columns(train_data, columns_to_drop)\n",
    "    logging.info(f\"Columns in the dataset after dropping: {train_data.columns.tolist()}\")\n",
    "    \n",
    "    logging.info(\"Preprocessing data...\")\n",
    "    X_train, y_train, imputer, scaler = preprocess_data(train_data, categorical_cols, numerical_cols, target_col)\n",
    "    \n",
    "    # Train the model\n",
    "    logging.info(\"Training the model...\")\n",
    "    final_model = train_model(X_train, y_train)\n",
    "\n",
    "    # Save the model, imputer, and scaler\n",
    "    logging.info(\"Saving the model, imputer, and scaler...\")\n",
    "    save_model(final_model, imputer, scaler, model_path, imputer_path, scaler_path)\n",
    "\n",
    "    logging.info(\"Model training completed and saved.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Operacion  Cant. Cuotas  Capital actual  Edad  INGRESO_CLIENTE  \\\n",
      "0   14515791            12         2357000    30        2550307.0   \n",
      "1   14518998            18         1178500    28        2000000.0   \n",
      "2   14522924            10         3535500    54        2000000.0   \n",
      "3   14525445            12         2946250    57        2289324.0   \n",
      "4   14526233            10         1178500    48        3500000.0   \n",
      "\n",
      "   Valor Cuota  Banca CALIFICACION_ANTERIOR  MARCA SEXO  Tipo  \\\n",
      "0       254000    420                   EXE      4    M   205   \n",
      "1       101000    130                   NaN      1    F   201   \n",
      "2       435000    130                   EXE      1    M   305   \n",
      "3       317000    240                   EXE      1    M   305   \n",
      "4       147000    420                   EXE      4    M   205   \n",
      "\n",
      "           Departamento  Medio  \\\n",
      "0  CENTRAL                  74   \n",
      "1  CENTRAL                  95   \n",
      "2  ALTO PARANA              96   \n",
      "3  AMAMBAY                  96   \n",
      "4  CENTRAL                 112   \n",
      "\n",
      "                                               Canal  \n",
      "0  TLMK CREDIMARKET                              ...  \n",
      "1  TELEMARKETING                                 ...  \n",
      "2  FF.VV. INTERIOR                               ...  \n",
      "3  FF.VV. INTERIOR                               ...  \n",
      "4  TLMK CREDIMARKET                              ...  \n",
      "Predictions completed and saved.\n",
      "   Operacion  Confidence\n",
      "0   14515791  832.961968\n",
      "1   14518998  439.139693\n",
      "2   14522924  830.787417\n",
      "3   14525445  937.831619\n",
      "4   14526233  947.801541\n",
      "5   14526808  800.895089\n",
      "6   14528723  916.605622\n",
      "7   14530159  697.192889\n",
      "8   14534851  637.703373\n",
      "9   14536372  899.313287\n"
     ]
    }
   ],
   "source": [
    "# Load the trained model, imputer, and scaler\n",
    "model_path = '/Users/fabrizioferrari/Desktop/final boss/catboost_model.cbm'\n",
    "final_model = CatBoostClassifier()\n",
    "final_model.load_model(model_path)\n",
    "\n",
    "imputer = joblib.load('/Users/fabrizioferrari/Desktop/final boss/imputer.pkl')\n",
    "scaler = joblib.load('/Users/fabrizioferrari/Desktop/final boss/scaler.pkl')\n",
    "\n",
    "# Load the new CSV file for testing\n",
    "test_file_path = '/Users/fabrizioferrari/Desktop/final boss/Test_Set_Condensed_Stripped.csv'\n",
    "test_data = pd.read_csv(test_file_path, delimiter=',')\n",
    "test_data.columns = test_data.columns.str.strip()  # Strip spaces from column names\n",
    "\n",
    "# Extract the 'Operacion' column for final output and ensure alignment\n",
    "test_operacion_column = test_data['Operacion']\n",
    "\n",
    "# Apply filtering conditions on the test data (ensure consistency with training data)\n",
    "test_data_filtered = test_data.copy()  # Create a copy for alignment\n",
    "test_data_filtered = test_data_filtered[test_data_filtered['SEXO'].isin(['M', 'F'])]\n",
    "test_data_filtered = test_data_filtered[(test_data_filtered['Edad'] <= 90) & (test_data_filtered['Edad'] >= 18)]\n",
    "test_data_filtered = test_data_filtered[(test_data_filtered['INGRESO_CLIENTE'] <= 500000001) & (test_data_filtered['INGRESO_CLIENTE'] >= 1000000)]\n",
    "test_data_filtered = test_data_filtered[(test_data_filtered['Cant. Cuotas'] <= 24) & (test_data_filtered['Cant. Cuotas'] >= 1)]\n",
    "test_data_filtered = test_data_filtered[(test_data_filtered['Capital actual'] <= 30000000) & (test_data_filtered['Capital actual'] >= 300000)]\n",
    "test_data_filtered = test_data_filtered[(test_data_filtered['Valor Cuota'] <= 10000000) & (test_data_filtered['Valor Cuota'] >= 50000)]\n",
    "test_data_filtered = test_data_filtered[test_data_filtered['Banca'].isin([240, 420, 130, 471, 421, 470])]\n",
    "test_data_filtered = test_data_filtered[test_data_filtered['Tipo'].isin([201, 205, 300, 305, 200])]\n",
    "\n",
    "print(test_data_filtered.head())\n",
    "\n",
    "# Ensure that 'Operacion' is aligned with the filtered data\n",
    "test_operacion_column = test_operacion_column.loc[test_data_filtered.index]\n",
    "\n",
    "# Categorical columns to encode\n",
    "categorical_cols = [\n",
    "    \"Banca\", \"CALIFICACION_ANTERIOR\", \"MARCA\", \"SEXO\", \"Tipo\", \"Departamento\", \"Medio\", \"Canal\"\n",
    "]\n",
    "\n",
    "# Encode categorical variables in the test data\n",
    "test_data_encoded = pd.get_dummies(test_data_filtered, columns=categorical_cols)\n",
    "\n",
    "# Align the test data with the training data (imputed features)\n",
    "missing_cols = set(imputer.feature_names_in_) - set(test_data_encoded.columns)\n",
    "for col in missing_cols:\n",
    "    test_data_encoded[col] = 0\n",
    "test_data_encoded = test_data_encoded[imputer.feature_names_in_]\n",
    "\n",
    "# Handle missing values in the test data\n",
    "X_test_imputed = imputer.transform(test_data_encoded)\n",
    "\n",
    "# Feature Scaling for the test data\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_predictions = final_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate the confidence scores\n",
    "test_confidences = 1000 - final_model.predict_proba(X_test_scaled)[:, 1] * 1000  # Scale to 0-1000\n",
    "\n",
    "# Create a DataFrame with the test set actual and predicted values\n",
    "results_df = pd.DataFrame({\n",
    "    'Operacion': test_operacion_column,\n",
    "    'Confidence': test_confidences\n",
    "})\n",
    "\n",
    "# Save the results DataFrame to a new CSV file\n",
    "output_file_path = '/Users/fabrizioferrari/Desktop/final boss/new_predictions.csv'\n",
    "results_df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"Predictions completed and saved.\")\n",
    "print(results_df.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
